<!DOCTYPE html>
<html lang="en">
<head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-9MK04KZZSD"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-9MK04KZZSD');
    </script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>StarC Language Specification</title>
    <meta name="description" content="StarC: A C-like parallel programming language for 4,096 processors in a 12-dimensional hypercube. Data-parallel computing inspired by the Connection Machine CM-1.">
    <link rel="icon" type="image/svg+xml" href="/img/logo2.svg">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Bahnschrift', 'DIN Alternate', Arial, sans-serif;
            line-height: 1.6;
            color: #1a1a1a;
            background: #e8e8e8;
        }

        header {
            background: #2a2a2a;
            border-bottom: 3px solid #0066cc;
            padding: 15px 20px;
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            z-index: 100;
            display: flex;
            align-items: center;
            gap: 15px;
        }

        .logo-small {
            height: 40px;
            width: auto;
        }

        header h1 {
            font-size: 1.5rem;
            color: #fff;
            letter-spacing: 2px;
        }

        header a {
            color: #0066cc;
            text-decoration: none;
            margin-left: auto;
            font-size: 0.9rem;
            font-weight: 700;
        }

        header a:hover {
            text-decoration: underline;
        }

        .container {
            display: flex;
            margin-top: 70px;
            min-height: calc(100vh - 70px);
        }

        .sidebar {
            width: 280px;
            background: #fff;
            border-right: 2px solid #333;
            position: fixed;
            top: 70px;
            left: 0;
            bottom: 0;
            overflow-y: auto;
            padding: 20px;
        }

        .sidebar h2 {
            font-size: 1rem;
            color: #0066cc;
            margin-bottom: 15px;
            text-transform: uppercase;
            letter-spacing: 1px;
        }

        .toc {
            list-style: none;
        }

        .toc li {
            margin-bottom: 8px;
        }

        .toc a {
            color: #333;
            text-decoration: none;
            font-size: 0.9rem;
            display: block;
            padding: 4px 0;
        }

        .toc a:hover {
            color: #0066cc;
        }

        .toc .toc-h1 {
            font-weight: 700;
            margin-top: 15px;
            font-size: 1rem;
        }

        .toc .toc-h1 a {
            color: #0066cc;
        }

        .toc .toc-h2 {
            font-weight: 700;
            margin-top: 12px;
            padding-left: 10px;
        }

        .toc .toc-h3 {
            padding-left: 25px;
            font-size: 0.85rem;
            color: #666;
        }

        .content {
            margin-left: 280px;
            padding: 40px;
            background: #fff;
            min-height: 100%;
            flex: 1;
        }

        .content h1 {
            font-size: 2.5rem;
            color: #1a1a1a;
            margin-top: 60px;
            margin-bottom: 30px;
            border-bottom: 3px solid #0066cc;
            padding-bottom: 15px;
        }

        .content h1:first-of-type {
            margin-top: 0;
        }

        /* Part headers with logos */
        .starc-part-header {
            display: grid;
            grid-template-columns: 100px 1fr;
            gap: 25px;
            align-items: center;
            margin-top: 60px;
            margin-bottom: 30px;
            padding-bottom: 15px;
            border-bottom: 3px solid #0066cc;
        }

        .content > .starc-part-header:first-child {
            margin-top: 0;
        }

        .starc-part-header img {
            width: 100%;
            height: auto;
            border: none !important;
            margin: 0;
        }

        .starc-part-header h1 {
            font-size: 2.5rem;
            color: #1a1a1a;
            margin: 0;
            border: none;
            padding: 0;
        }

        @media (max-width: 768px) {
            .starc-part-header {
                grid-template-columns: 70px 1fr;
                gap: 15px;
            }

            .starc-part-header h1 {
                font-size: 1.8rem;
            }
        }

        .content h2 {
            font-size: 1.8rem;
            color: #1a1a1a;
            margin-top: 50px;
            margin-bottom: 20px;
            border-bottom: 2px solid #0066cc;
            padding-bottom: 10px;
        }

        .content h3 {
            font-size: 1.3rem;
            color: #0066cc;
            margin-top: 35px;
            margin-bottom: 15px;
        }

        .content h4 {
            font-size: 1.1rem;
            color: #333;
            margin-top: 25px;
            margin-bottom: 10px;
        }

        .content p {
            margin-bottom: 15px;
            line-height: 1.7;
        }

        .content pre {
            background: #f5f5f5;
            color: #1a1a1a;
            padding: 20px;
            overflow-x: auto;
            font-size: 0.9rem;
            line-height: 1.5;
            margin: 20px 0;
            border: 2px solid #333;
            font-family: 'Consolas', 'Monaco', 'Courier New', monospace;
        }

        .content code {
            font-family: 'Consolas', 'Monaco', 'Courier New', monospace;
            background: #e8e8e8;
            padding: 2px 6px;
            border-radius: 3px;
            font-size: 0.9em;
            color: #1a1a1a;
        }

        .content pre code {
            background: transparent;
            padding: 0;
            border-radius: 0;
        }

        .content ul, .content ol {
            margin-left: 25px;
            margin-bottom: 15px;
        }

        .content li {
            margin-bottom: 8px;
        }

        .content blockquote {
            border-left: 4px solid #0066cc;
            padding-left: 20px;
            margin: 20px 0;
            color: #555;
            font-style: italic;
        }

        .content table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            border: 2px solid #333;
        }

        .content th, .content td {
            border: 1px solid #333;
            padding: 10px;
            text-align: left;
        }

        .content th {
            background: #2a2a2a;
            color: #fff;
            font-weight: 700;
        }

        .content a {
            color: #0066cc;
            text-decoration: none;
        }

        .content a:hover {
            text-decoration: underline;
        }

        .content hr {
            display: none;
        }

        .content img {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 20px auto;
            border: 2px solid #333;
        }

        /* Collapsible code blocks */
        .code-block-wrapper.collapsible {
            margin: 20px 0;
            border: 2px solid #333;
            overflow: hidden;
        }

        .code-block-wrapper.collapsible .code-block-header {
            background: #0066cc;
            color: white;
            padding: 10px 20px;
            display: flex;
            justify-content: space-between;
            align-items: center;
            cursor: pointer;
            user-select: none;
        }

        .code-block-wrapper.collapsible .code-block-header:hover {
            background: #0052a3;
        }

        .code-block-wrapper.collapsible .code-block-title {
            font-weight: 700;
            font-size: 0.9rem;
            letter-spacing: 1px;
        }

        .code-block-wrapper.collapsible .code-block-toggle {
            font-size: 0.85rem;
            padding: 4px 12px;
            background: rgba(255, 255, 255, 0.2);
            border-radius: 3px;
            font-weight: 700;
        }

        .code-block-wrapper.collapsible .code-block-content {
            display: none;
            max-height: 500px;
            overflow: auto;
        }

        .code-block-wrapper.collapsible .code-block-content.expanded {
            display: block;
        }

        .code-block-wrapper.collapsible .code-block-content pre {
            margin: 0;
            border: none;
            border-radius: 0;
        }

        .mobile-menu-btn {
            display: none;
            position: fixed;
            bottom: 20px;
            right: 20px;
            background: #0066cc;
            color: #fff;
            border: none;
            padding: 15px;
            font-size: 1.2rem;
            border-radius: 50%;
            width: 60px;
            height: 60px;
            cursor: pointer;
            z-index: 200;
            box-shadow: 0 4px 12px rgba(0,0,0,0.3);
        }

        @media (max-width: 768px) {
            .sidebar {
                transform: translateX(-100%);
                transition: transform 0.3s;
                z-index: 150;
                width: 80%;
                max-width: 300px;
            }

            .sidebar.open {
                transform: translateX(0);
            }

            .content {
                margin-left: 0;
                padding: 15px;
                width: 100%;
                max-width: 100%;
            }

            .content pre {
                padding: 12px;
                font-size: 0.8rem;
            }

            .mobile-menu-btn {
                display: block;
            }

            header h1 {
                font-size: 1.2rem;
            }
        }
    </style>
</head>
<body>
    <header>
        <a href="/"><img src="/img/logo2.svg" alt="StarC" class="logo-small"></a>
        <h1>STARC SPECIFICATION</h1>
        <a href="/">HOME</a>
    </header>

    <div class="container">
        <nav class="sidebar" id="sidebar">
            <h2>Contents</h2>
            <ul class="toc" id="toc">
                <li><a href="#starc-a-parallel-c-for-hypercube-computers" class="toc-h1">StarC: A Parallel C for Hypercube Computers</a></li>
                <li><a href="#introduction" class="toc-h2">Introduction</a></li>
                <li><a href="#implementation" class="toc-h3">Implementation</a></li>
                <li><a href="#part-i-the-machine" class="toc-h1">Part I: The Machine</a></li>
                <li><a href="#chapter-1-hardware-model" class="toc-h2">Chapter 1: Hardware Model</a></li>
                <li><a href="#dual-networks" class="toc-h3">Dual Networks</a></li>
                <li><a href="#tdma-timing" class="toc-h3">TDMA Timing</a></li>
                <li><a href="#message-framing" class="toc-h3">Message Framing</a></li>
                <li><a href="#addressing" class="toc-h3">Addressing</a></li>
                <li><a href="#the-led-array" class="toc-h3">The LED Array</a></li>
                <li><a href="#chapter-2-design-constraints" class="toc-h2">Chapter 2: Design Constraints</a></li>
                <li><a href="#what-the-cm-1-had" class="toc-h3">What the CM-1 Had</a></li>
                <li><a href="#what-this-machine-has-instead" class="toc-h3">What This Machine Has Instead</a></li>
                <li><a href="#how-these-differences-shape-the-language" class="toc-h3">How These Differences Shape the Language</a></li>
                <li><a href="#why-no-arbitrary-routing" class="toc-h3">Why No Arbitrary Routing?</a></li>
                <li><a href="#design-principles" class="toc-h3">Design Principles</a></li>
                <li><a href="#part-ii-the-language" class="toc-h1">Part II: The Language</a></li>
                <li><a href="#chapter-3-data-model" class="toc-h2">Chapter 3: Data Model</a></li>
                <li><a href="#parallel-variables" class="toc-h3">Parallel Variables</a></li>
                <li><a href="#scalars" class="toc-h3">Scalars</a></li>
                <li><a href="#processor-identity" class="toc-h3">Processor Identity</a></li>
                <li><a href="#type-limits" class="toc-h3">Type Limits</a></li>
                <li><a href="#struct-padding" class="toc-h3">Struct Padding</a></li>
                <li><a href="#arrays-of-pvars" class="toc-h3">Arrays of Pvars</a></li>
                <li><a href="#chapter-4-control-flow" class="toc-h2">Chapter 4: Control Flow</a></li>
                <li><a href="#two-phase-execution" class="toc-h3">Two-Phase Execution</a></li>
                <li><a href="#uniform-control-flow" class="toc-h3">Uniform Control Flow</a></li>
                <li><a href="#divergent-control-flow" class="toc-h3">Divergent Control Flow</a></li>
                <li><a href="#nesting" class="toc-h3">Nesting</a></li>
                <li><a href="#functions" class="toc-h3">Functions</a></li>
                <li><a href="#chapter-5-communication" class="toc-h2">Chapter 5: Communication</a></li>
                <li><a href="#exchange-blocks" class="toc-h3">Exchange Blocks</a></li>
                <li><a href="#neighbor-exchange-nbr" class="toc-h3">Neighbor Exchange: nbr()</a></li>
                <li><a href="#grid-neighbors-news" class="toc-h3">Grid Neighbors: news()</a></li>
                <li><a href="#diagonal-neighbors" class="toc-h3">Diagonal Neighbors</a></li>
                <li><a href="#reductions" class="toc-h3">Reductions</a></li>
                <li><a href="#scans-prefix-operations" class="toc-h3">Scans (Prefix Operations)</a></li>
                <li><a href="#broadcast" class="toc-h3">Broadcast</a></li>
                <li><a href="#double-buffering" class="toc-h3">Double Buffering</a></li>
                <li><a href="#chapter-6-host-io" class="toc-h2">Chapter 6: Host I/O</a></li>
                <li><a href="#bulk-data-transfer" class="toc-h3">Bulk Data Transfer</a></li>
                <li><a href="#console-output" class="toc-h3">Console Output</a></li>
                <li><a href="#led-control" class="toc-h3">LED Control</a></li>
                <li><a href="#part-iii-programming" class="toc-h1">Part III: Programming</a></li>
                <li><a href="#chapter-7-patterns" class="toc-h2">Chapter 7: Patterns</a></li>
                <li><a href="#dimension-walk" class="toc-h3">Dimension Walk</a></li>
                <li><a href="#bitonic-sort" class="toc-h3">Bitonic Sort</a></li>
                <li><a href="#heat-equation" class="toc-h3">Heat Equation</a></li>
                <li><a href="#global-statistics" class="toc-h3">Global Statistics</a></li>
                <li><a href="#parallel-prefix-exclusive-and-inclusive" class="toc-h3">Parallel Prefix (Exclusive and Inclusive)</a></li>
                <li><a href="#stream-compaction" class="toc-h3">Stream Compaction</a></li>
                <li><a href="#news-blur" class="toc-h3">NEWS Blur</a></li>
                <li><a href="#conway39s-game-of-life" class="toc-h3">Conway&#39;s Game of Life</a></li>
                <li><a href="#double-buffered-stencil" class="toc-h3">Double-Buffered Stencil</a></li>
                <li><a href="#random-and-pleasing" class="toc-h3">Random and Pleasing</a></li>
                <li><a href="#chapter-8-performance" class="toc-h2">Chapter 8: Performance</a></li>
                <li><a href="#timing-model" class="toc-h3">Timing Model</a></li>
                <li><a href="#exchange-scheduling" class="toc-h3">Exchange Scheduling</a></li>
                <li><a href="#automatic-reordering" class="toc-h3">Automatic Reordering</a></li>
                <li><a href="#bandwidth" class="toc-h3">Bandwidth</a></li>
                <li><a href="#mcu-utilization" class="toc-h3">MCU Utilization</a></li>
                <li><a href="#phase-rate-trade-offs" class="toc-h3">Phase Rate Trade-offs</a></li>
                <li><a href="#iteration-rates" class="toc-h3">Iteration Rates</a></li>
                <li><a href="#part-iv-implementation" class="toc-h1">Part IV: Implementation</a></li>
                <li><a href="#chapter-9-toolchain" class="toc-h2">Chapter 9: Toolchain</a></li>
                <li><a href="#build-pipeline" class="toc-h3">Build Pipeline</a></li>
                <li><a href="#preprocessor-transformations" class="toc-h3">Preprocessor Transformations</a></li>
                <li><a href="#preprocessor-diagnostics" class="toc-h3">Preprocessor Diagnostics</a></li>
                <li><a href="#compiler-settings" class="toc-h3">Compiler Settings</a></li>
                <li><a href="#backends" class="toc-h3">Backends</a></li>
                <li><a href="#chapter-10-runtime" class="toc-h2">Chapter 10: Runtime</a></li>
                <li><a href="#exchange-block-compilation" class="toc-h3">Exchange Block Compilation</a></li>
                <li><a href="#fpga-interface" class="toc-h3">FPGA Interface</a></li>
                <li><a href="#phase-rate-configuration" class="toc-h3">Phase Rate Configuration</a></li>
                <li><a href="#error-handling" class="toc-h3">Error Handling</a></li>
                <li><a href="#appendices" class="toc-h1">Appendices</a></li>
                <li><a href="#appendix-a-quick-reference" class="toc-h2">Appendix A: Quick Reference</a></li>
                <li><a href="#types-and-identity" class="toc-h3">Types and Identity</a></li>
                <li><a href="#communication-exchange-blocks-only" class="toc-h3">Communication (exchange blocks only)</a></li>
                <li><a href="#control" class="toc-h3">Control</a></li>
                <li><a href="#io-control-tree" class="toc-h3">I/O (control tree)</a></li>
                <li><a href="#configuration" class="toc-h3">Configuration</a></li>
                <li><a href="#appendix-b-what-starc-doesn39t-have" class="toc-h2">Appendix B: What StarC Doesn&#39;t Have</a></li>
                <li><a href="#appendix-c-constants" class="toc-h2">Appendix C: Constants</a></li>
                <li><a href="#appendix-d-reduction-and-scan-order" class="toc-h2">Appendix D: Reduction and Scan Order</a></li>
                <li><a href="#finally" class="toc-h1">Finally...</a></li>

            </ul>
        </nav>

        <main class="content" id="content">
<div class="starc-part-header">
  <img src="/img/logo2.svg" alt="StarC Logo">
  <h1 id="starc-a-parallel-c-for-hypercube-computers">StarC: A Parallel C for Hypercube Computers</h1>
</div>

<h2 id="introduction">Introduction</h2>
<p>The C programming language is a product of the DEC PDP-11. C is the way it is because that&#39;s how the PDP-11 worked. <code>++</code> and <code>--</code> exist because the PDP-11 had auto-increment addressing modes. <code>*p++</code> isn&#39;t a trick; it&#39;s built into the hardware. Strings in C are <code>char</code> arrays with a 0 at the end, because that&#39;s what the PDP-11 did. C has no checks for array bounds because the PDP-11 didn&#39;t check array bounds in hardware. There&#39;s nothing wrong with what C does; like most things it is a product of the material conditions of its development.</p>
<p>StarC is what those material conditions look like for a hypercube.</p>
<p>This language was developed in parallel with a machine with 4,096 RISC-V microcontrollers arranged as a 12-dimensional hypercube. Each processor has 12 neighbors. Communication happens over a time-division multiplexed serial network with deterministic timing. This machine is obviously inspired by the Thinking Machines Connection Machine CM-1. There were two programming languages for the CM-1: C* and *Lisp. Both are dead. The machines that ran these languages are all powered down. If you want to program a hypercube machine in the 21st century, you&#39;re on your own. StarC was created to program this machine.</p>
<p>There are subtle but significant differences between the Connection Machine CM-1 and the machine this language was designed for. The CM-1 had dedicated router ASICs at each node for arbitrary point-to-point communication. This machine doesn&#39;t. It has a TDMA schedule and neighbor links, nothing more. The CM-1 had 1-bit processors with hardware masking for true SIMD execution. This machine has 32-bit RISC-V cores running SPMD, but each processor executes independently. The CM-1 could hide communication latency behind its router. This machine cannot. The network schedule is visible, and communication happens when the schedule says it happens.</p>
<p>These differences shape the language. No router means no <code>get(arbitrary_address)</code>. StarC only has neighbor exchange. TDMA means communication is batched into explicit <code>exchange</code> blocks, not scattered through code. SPMD means <code>where</code> is just syntax for <code>if</code>, not a hardware mask operation. The constraints of C* came from the CM-1&#39;s hardware. The constraints of StarC come from this machine&#39;s hardware.</p>
<h3 id="implementation">Implementation</h3>
<p>In implementation, StarC compiles to C via a Python preprocessor. That&#39;s it. There is no virtual machine or garbage collector or runtime type system. The Python preprocessor rewrites <code>pvar&lt;T&gt;</code>, <code>where</code>, and <code>exchange</code> blocks into C with runtime calls. The runtime handles TDMA timing and communication. There&#39;s no magic, only just enough syntax to express hypercube algorithms without fighting the hardware. C was, and is, a thin wrapper over the PDP-11. StarC is a thin wrapper over a hypercube.</p>
<p>Calling StarC an overcomplication of what could be a bunch of macros is probably correct. However, GCC has no idea about the rules of a hypercube. With StarC, exchange blocks can be validated, there is no accidental dependence on ordering, and no weird multi-superframe behavior. StarC exists to enforce the rules of the machine and illustrate what is possible within the confines of the hardware. Like C did with a PDP-11.</p>
<p><strong>Recommended reading providing context to this specification</strong></p>
<ul>
<li><a href="https://bbenchoff.github.io/pages/ThinkinMachine.html">Recreating the Connection Machine: 4,096 RISC-V Cores in a Hypercube</a></li>
<li><a href="https://bbenchoff.github.io/pages/HypercubeTDMA.html">TDMA Routing on a Hypercube</a></li>
</ul>
<div class="starc-part-header">
  <img src="/img/logo2.svg" alt="StarC Logo">
  <h1 id="part-i-the-machine">Part I: The Machine</h1>
</div>

<h2 id="chapter-1-hardware-model">Chapter 1: Hardware Model</h2>
<p>Before writing StarC code, you need to understand the machine StarC was designed for. StarC was created for exactly one machine: a massively parallel array of microcontrollers that communicate through a hypercube network where messages are passed with a time-division multiplex communications scheme. It is highly recommended you <a href="https://bbenchoff.github.io/pages/HypercubeTDMA.html">read about the TDMA routing</a> before digging into this.</p>
<h3 id="dual-networks">Dual Networks</h3>
<p>The machine has two independent networks:</p>
<p><strong>1. Hypercube Network (TDMA)</strong></p>
<p>The primary communication network. A 12-dimensional hypercube connecting all 4,096 processors. Each processor has 12 neighbors—one per dimension. Communication is time-division multiplexed over a single UART per processor. Deterministic latency: every operation completes in bounded time.</p>
<p>This network handles: neighbor exchange, reductions, scans, broadcasts.</p>
<p><strong>2. Control Tree Network</strong></p>
<p>A hierarchical network separate from the hypercube. The structure is:</p>
<ul>
<li>16 nodes per slice controller</li>
<li>16 slice controllers per plane controller  </li>
<li>16 plane controllers per machine controller</li>
<li>Machine controller connects to host PC</li>
</ul>
<p>Physical connections are single-wire serial from slice controllers to nodes. Higher bandwidth than the hypercube for bulk transfers, but variable latency.</p>
<p>This network handles: programming nodes, LED updates, bulk data transfer, host I/O.</p>
<pre><code>                    ┌──────────────┐
                    │    Host PC   │
                    └──────┬───────┘
                           │ USB
                    ┌──────┴───────┐
                    │   Machine    │
                    │  Controller  │
                    └──────┬───────┘
           ┌───────────────┼───────────────┐
           │               │               │
    ┌──────┴──────┐ ┌──────┴──────┐ ┌──────┴──────┐
    │    Plane    │ │    Plane    │ │    Plane    │  (×16)
    │  Controller │ │  Controller │ │  Controller │
    └──────┬──────┘ └──────┬──────┘ └──────┬──────┘
           │               │               │
      ┌────┴────┐     ┌────┴────┐     ┌────┴────┐
      │  Slice  │     │  Slice  │     │  Slice  │     (×16 per plane)
      │Controller│    │Controller│    │Controller│
      └────┬────��     └────┬────┘     └────┬────┘
           │               │               │
       ┌───┴───┐       ┌───┴───┐       ┌───┴───┐
       │ Nodes │       │ Nodes │       │ Nodes │      (×16 per slice)
       │ 0-15  │       │ 0-15  │       │ 0-15  │
       └───────┘       └───────┘       └───────┘
</code></pre>
<p>StarC communication primitives use the hypercube network. Host I/O functions use the control tree.</p>
<h3 id="tdma-timing">TDMA Timing</h3>
<p>The hypercube network operates on a fixed schedule. Time is divided into phases, and phases are grouped into superframes.</p>
<p><strong>Default timing configuration:</strong></p>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Value</th>
</tr>
</thead>
<tbody><tr>
<td>Phase clock</td>
<td>1 kHz</td>
</tr>
<tr>
<td>Phase duration</td>
<td>1 ms</td>
</tr>
<tr>
<td>Phases per superframe</td>
<td>24</td>
</tr>
<tr>
<td>Superframe duration</td>
<td>24 ms</td>
</tr>
<tr>
<td>Serial baud rate</td>
<td>1 Mbps</td>
</tr>
<tr>
<td>Payload per phase</td>
<td>80 bytes</td>
</tr>
</tbody></table>
<p>Each of the 12 dimensions gets two phases per superframe: one for each direction. In dimension <em>d</em>, processors with bit <em>d</em> = 0 transmit first, then processors with bit <em>d</em> = 1 transmit. Dimension 0 uses phases 0-1. Dimension 11 uses phases 22-23.</p>
<p><strong>TDMA properties:</strong></p>
<ul>
<li><strong>No collisions.</strong> Each link has exactly one transmitter per phase. The schedule guarantees this.</li>
<li><strong>No arbitrary routing.</strong> There is no <code>get(address)</code> or <code>send(address, value)</code>. You cannot send a message to an arbitrary processor. You can only exchange with your 12 hypercube neighbors.</li>
<li><strong>No adaptive forwarding.</strong> Packets don&#39;t route around congestion. There is no congestion—the schedule determines everything.</li>
<li><strong>Multi-hop collectives exist</strong> but are implemented as structured tree algorithms over neighbor links, not general routing. A reduction traverses dimensions 0→11 in order, exchanging with neighbors at each step. The path is fixed, not computed per-packet.</li>
</ul>
<h3 id="message-framing">Message Framing</h3>
<p>Each phase transmits one frame:</p>
<pre><code>┌──────┬────────┬────────┬─────────────────┬───────┐
│ Sync │ Header │ Length │     Payload     │ CRC16 │
│  1B  │   1B   │   1B   │    0-80 B       │  2B   │
└──────┴────────┴────────┴─────────────────┴───────┘
</code></pre>
<table>
<thead>
<tr>
<th>Field</th>
<th>Size</th>
<th>Description</th>
</tr>
</thead>
<tbody><tr>
<td>Sync</td>
<td>1 byte</td>
<td>0xAA — byte alignment</td>
</tr>
<tr>
<td>Header</td>
<td>1 byte</td>
<td>Flags and metadata</td>
</tr>
<tr>
<td>Length</td>
<td>1 byte</td>
<td>Payload length (0-80)</td>
</tr>
<tr>
<td>Payload</td>
<td>0-80 bytes</td>
<td>User data</td>
</tr>
<tr>
<td>CRC-16</td>
<td>2 bytes</td>
<td>Error detection</td>
</tr>
</tbody></table>
<p>At 1 Mbps with 1 ms phases, approximately 100 bytes can transit per phase. After framing overhead and timing margins, 80 bytes of payload remain.</p>
<h3 id="addressing">Addressing</h3>
<p>The 4,096 processors can be viewed two ways.</p>
<p><strong>Hypercube view:</strong> Each processor has a 12-bit address (0-4095). Two processors are neighbors if their addresses differ by exactly one bit. Processor 0x2A3 has neighbors at 0x2A2 (bit 0 differs), 0x2A1 (bit 1 differs), 0x2A7 (bit 2 differs), and so on for all 12 bits.</p>
<p><strong>Grid view:</strong> The processors form a 64×64 toroidal grid. Each processor has a row (0-63) and column (0-63). The grid wraps: row 0&#39;s north neighbor is row 63, column 63&#39;s east neighbor is column 0.</p>
<p>These views are equivalent through Gray code mapping:</p>
<pre><code class="language-c">// Convert grid position to processor ID
int grid_to_pid(int row, int col) {
    int gray_row = row ^ (row &gt;&gt; 1);  // 6-bit Gray code
    int gray_col = col ^ (col &gt;&gt; 1);  // 6-bit Gray code
    return (gray_row &lt;&lt; 6) | gray_col;
}
</code></pre>
<p><strong>Why Gray code?</strong> In Gray code, adjacent values differ by exactly one bit. Moving one step in any cardinal direction—including wrapping at edges—changes exactly one bit of the address. Every NEWS direction is exactly one hypercube hop.</p>
<p><strong>Dimension mapping:</strong></p>
<ul>
<li>Bits 0-5 (dimensions 0-5): column position</li>
<li>Bits 6-11 (dimensions 6-11): row position</li>
<li>EAST/WEST movement: dimensions 0-5</li>
<li>NORTH/SOUTH movement: dimensions 6-11</li>
</ul>
<h3 id="the-led-array">The LED Array</h3>
<p>Each processor has one LED. The 64×64 LED matrix maps directly to the 64×64 grid view. Position (row, col) shows the LED of the processor at that grid position.</p>
<p>LEDs are updated via the control tree, not the hypercube network. Setting an LED is a local operation that doesn&#39;t require an exchange block.</p>
<hr>
<h2 id="chapter-2-design-constraints">Chapter 2: Design Constraints</h2>
<p>The CM-1 and this machine are both hypercubes. But they&#39;re built differently, and those differences determine what the programming language can and cannot do.</p>
<h3 id="what-the-cm-1-had">What the CM-1 Had</h3>
<p><strong>Router ASICs.</strong> Every CM-1 node had a dedicated routing chip that could accept messages at any time, buffer them, and forward them toward their destination. This enabled arbitrary point-to-point communication. Any processor could send a message to any other processor.</p>
<p><strong>1-bit processors with hardware masking.</strong> The CM-1 processors were 1-bit wide and operated in true SIMD fashion. A global instruction stream controlled all processors simultaneously. Hardware masking disabled processors that shouldn&#39;t participate in an operation—they still executed the instruction, but results were discarded.</p>
<p><strong>Hidden latency.</strong> The router buffered messages and handled delivery asynchronously. A program could issue a send and continue computing while the router worked.</p>
<h3 id="what-this-machine-has-instead">What This Machine Has Instead</h3>
<p><strong>TDMA schedule and neighbor links.</strong> No router. Each processor can only talk to its 12 hypercube neighbors, and only during the scheduled phases. There&#39;s no buffering, no forwarding, no arbitrary addressing.</p>
<p><strong>32-bit RISC-V cores running SPMD.</strong> Each processor is a full 32-bit microcontroller executing independently. There&#39;s no global instruction stream. Processors run the same program but make independent control flow decisions. &quot;Masking&quot; is just <code>if</code> statements.</p>
<p><strong>Visible latency.</strong> Communication happens when the schedule says it happens. If you miss a phase, you wait for the next superframe. The network timing is part of the programming model.</p>
<h3 id="how-these-differences-shape-the-language">How These Differences Shape the Language</h3>
<p><strong>No router → no <code>get(arbitrary_address)</code>.</strong></p>
<p>C* and *Lisp had primitives to read from or write to any processor. This requires routing through intermediate nodes. We can&#39;t do that—we have no router. StarC only has neighbor exchange: <code>nbr(dimension, value)</code> swaps values with your neighbor in that dimension. Everything else is built on top of that.</p>
<p><strong>TDMA → explicit <code>exchange</code> blocks.</strong></p>
<p>In C*, you could scatter communication calls throughout your code. The router would handle them whenever. We can&#39;t do that—communication only works during the right phase. StarC batches all communication into explicit <code>exchange</code> blocks. Inside the block, you declare what exchanges you need. The runtime schedules them optimally within the TDMA superframe.</p>
<p><strong>SPMD → <code>where</code> is just <code>if</code>.</strong></p>
<p>In C*, <code>where</code> was a hardware operation that masked processors. Inactive processors still executed but discarded results. In StarC, <code>where</code> is syntactic sugar for <code>if</code>. Each processor independently decides whether to execute the body. There&#39;s no hardware masking—just conditional execution.</p>
<h3 id="why-no-arbitrary-routing">Why No Arbitrary Routing?</h3>
<p>Building a router is hard. The CM-1&#39;s router was a significant fraction of the machine&#39;s complexity and cost. We don&#39;t have the budget for custom ASICs.</p>
<p>But here&#39;s the thing: most parallel algorithms don&#39;t need arbitrary routing.</p>
<table>
<thead>
<tr>
<th>Algorithm</th>
<th>Communication Pattern</th>
<th>Needs Routing?</th>
</tr>
</thead>
<tbody><tr>
<td>Bitonic sort</td>
<td><code>pid XOR 2^k</code> — hypercube neighbor</td>
<td>No</td>
</tr>
<tr>
<td>Parallel prefix</td>
<td>Tree over dimensions</td>
<td>No</td>
</tr>
<tr>
<td>Reduction</td>
<td>Tree over dimensions</td>
<td>No</td>
</tr>
<tr>
<td>Stencils</td>
<td>NEWS neighbors</td>
<td>No</td>
</tr>
<tr>
<td>FFT</td>
<td>Dimension-ordered exchange</td>
<td>No</td>
</tr>
<tr>
<td>Matrix multiply</td>
<td>Broadcasts + local compute</td>
<td>No</td>
</tr>
<tr>
<td>Game of Life</td>
<td>8 neighbors</td>
<td>No</td>
</tr>
</tbody></table>
<p>Bitonic sort is the canonical example. The inner loop exchanges with <code>pid XOR j</code> where j is a power of 2. That&#39;s a single-bit difference—always a hypercube neighbor. The algorithm is topology-aware.</p>
<p>Algorithms that genuinely need arbitrary routing—sparse matrix, irregular graph traversal, hash tables—should use a GPU or a machine with a real interconnect. The hypercube excels at structured, topology-aware communication. StarC supports what the hypercube does well.</p>
<h3 id="design-principles">Design Principles</h3>
<p>These constraints lead to clear design principles:</p>
<ol>
<li><p><strong>Data is distributed.</strong> Each processor has its own data. There&#39;s no shared memory.</p>
</li>
<li><p><strong>Operations happen everywhere.</strong> When you write <code>x = x + 1</code>, all 4,096 processors increment their local <code>x</code>.</p>
</li>
<li><p><strong>Communication is batched.</strong> All exchanges go in <code>exchange</code> blocks. The runtime schedules them.</p>
</li>
<li><p><strong>The topology is visible.</strong> You know you&#39;re on a hypercube. You know what dimensions cost.</p>
</li>
<li><p><strong>Only hypercube-native operations.</strong> Neighbor exchange, tree reductions, broadcasts. No arbitrary permutation.</p>
</li>
</ol>
<div class="starc-part-header">
  <img src="/img/logo2.svg" alt="StarC Logo">
  <h1 id="part-ii-the-language">Part II: The Language</h1>
</div>

<h2 id="chapter-3-data-model">Chapter 3: Data Model</h2>
<p>This chapter covers how data is represented in StarC: parallel variables, scalars, and processor identity.</p>
<h3 id="parallel-variables">Parallel Variables</h3>
<p>A <code>pvar&lt;T&gt;</code> is a <strong>type qualifier</strong> meaning &quot;this value exists once per processor.&quot; In generated code, it&#39;s just a local variable—there&#39;s no distributed shared memory, no magic synchronization. Each of the 4,096 processors has its own independent copy.</p>
<pre><code class="language-c">pvar&lt;int&gt; x;              // 4,096 integers, one per processor
pvar&lt;float&gt; temperature;  // 4,096 floats
pvar&lt;point_t&gt; position;   // 4,096 structs
</code></pre>
<p>When you operate on a pvar, all processors execute the operation simultaneously:</p>
<pre><code class="language-c">x = 42;           // All 4,096 processors store 42
x = pid();        // Each processor stores its own ID (0-4095)
x = x + 1;        // All processors increment their local x
</code></pre>
<p><strong>Initial values are undefined.</strong> A freshly declared pvar contains garbage—whatever was in that memory location. Always initialize before use:</p>
<pre><code class="language-c">pvar&lt;int&gt; x;      // Undefined—could be anything
x = 0;            // Now defined
</code></pre>
<h3 id="scalars">Scalars</h3>
<p>Scalars are ordinary C variables. They have the same value on all processors:</p>
<pre><code class="language-c">int iterations = 1000;    // Same on all processors
float threshold = 0.001f; // Same on all processors
</code></pre>
<p>Scalars are used for control flow (loop counters, convergence flags) and constants. They&#39;re replicated, not distributed.</p>
<p><strong>Mixing scalars and pvars:</strong></p>
<pre><code class="language-c">pvar&lt;int&gt; x;
int scalar = 100;

x = scalar;          // Every processor stores 100
x = x + scalar;      // Every processor adds 100 to its x
x = x * 2;           // Every processor doubles its x
</code></pre>
<p><strong>You cannot assign a pvar to a scalar:</strong></p>
<pre><code class="language-c">int scalar = x;      // ERROR: which processor&#39;s x?
</code></pre>
<p>To get a scalar from parallel data, use a reduction:</p>
<pre><code class="language-c">int total = reduce_sum(x);   // Sum across all processors
int maximum = reduce_max(x); // Maximum across all processors
</code></pre>
<h3 id="processor-identity">Processor Identity</h3>
<p>Every processor knows who it is:</p>
<pre><code class="language-c">int pid()              // Hypercube address (0-4095)
int coord(int dim)     // Bit &#39;dim&#39; of the address (0 or 1)
int grid_row()         // Grid row (0-63)  
int grid_col()         // Grid column (0-63)
</code></pre>
<p>These are how you write position-dependent code:</p>
<pre><code class="language-c">pvar&lt;int&gt; x;
x = pid();            // Each processor stores its own ID

if (coord(0) == 1) {
    // Only processors with bit 0 set execute this
    // That&#39;s processors 1, 3, 5, 7, ... (odd addresses)
}

// Initialize based on grid position
pvar&lt;int&gt; distance_from_center;
int dr = grid_row() - 32;
int dc = grid_col() - 32;
distance_from_center = dr*dr + dc*dc;
</code></pre>
<h3 id="type-limits">Type Limits</h3>
<p><strong>Maximum pvar size for exchange: 80 bytes.</strong></p>
<p>This is the payload limit per phase at 1 kHz. If your struct exceeds this, you&#39;ll need to split exchanges or use a slower phase rate.</p>
<p><strong>No pointers in pvars:</strong></p>
<pre><code class="language-c">pvar&lt;int*&gt; ptr;       // ERROR: pointers don&#39;t make sense
</code></pre>
<p>A pointer on processor 17 pointing to processor 42&#39;s memory is meaningless—there&#39;s no shared address space.</p>
<p><strong>No nested pvars:</strong></p>
<pre><code class="language-c">pvar&lt;pvar&lt;int&gt;&gt; x;    // ERROR: doesn&#39;t make sense
</code></pre>
<h3 id="struct-padding">Struct Padding</h3>
<p>When approaching the 80-byte limit, padding matters:</p>
<pre><code class="language-c">// Bad: padding wastes space
typedef struct {
    char a;       // 1 byte
    int b;        // 4 bytes (3 bytes padding before)
    char c;       // 1 byte (3 bytes padding after)
} padded_t;       // 12 bytes!

// Good: ordered by size
typedef struct {
    int b;        // 4 bytes
    char a;       // 1 byte
    char c;       // 1 byte
} packed_t;       // 6 bytes (2 bytes trailing padding)

// Best: explicit packing
typedef struct __attribute__((packed)) {
    int b;
    char a;
    char c;
} tight_t;        // 6 bytes, no padding
</code></pre>
<p>Order struct members from largest to smallest, or use <code>__attribute__((packed))</code> when you need precise control.</p>
<h3 id="arrays-of-pvars">Arrays of Pvars</h3>
<p>Arrays of pvars create multiple values per processor:</p>
<pre><code class="language-c">pvar&lt;int&gt; buffer[256];    // Each processor has 256 integers
                          // Total: 4,096 × 256 = 1M integers
</code></pre>
<p>Indexing works as expected:</p>
<pre><code class="language-c">pvar&lt;int&gt; A[100];
int i = 50;               // Scalar index

A[i] = pid();             // All processors write to their A[50]

pvar&lt;int&gt; j = pid() % 100;  // Parallel index
pvar&lt;int&gt; val = A[j];       // Each processor reads a different element
</code></pre>
<hr>
<h2 id="chapter-4-control-flow">Chapter 4: Control Flow</h2>
<p>StarC distinguishes between uniform and divergent control flow. This distinction matters because exchange blocks require all processors to participate together.</p>
<h3 id="two-phase-execution">Two-Phase Execution</h3>
<p>StarC programs alternate between two phases:</p>
<p><strong>Compute phase:</strong> Local operations only. Arithmetic, memory access, control flow. No network communication.</p>
<pre><code class="language-c">data = expensive_math(data);
if (data &gt; threshold) data = threshold;
local_array[i] = data;
</code></pre>
<p><strong>Exchange phase:</strong> Network communication. Batched into explicit <code>exchange</code> blocks.</p>
<pre><code class="language-c">exchange {
    neighbor = nbr(0, data);
    total = reduce_sum(data);
}
</code></pre>
<p>The rhythm is: compute, exchange, compute, exchange. This matches the hardware: the MCU computes, then waits for the TDMA schedule to move data.</p>
<h3 id="uniform-control-flow">Uniform Control Flow</h3>
<p>Uniform control flow means all processors take the same path. The condition is a scalar—same value on all processors.</p>
<pre><code class="language-c">int threshold = 100;          // Scalar—same everywhere

if (threshold &gt; 50) {         // All processors take this branch
    data = data * 2;          // All processors execute this
}

for (int i = 0; i &lt; 10; i++) { // Scalar loop counter
    // All processors execute this loop 10 times
}
</code></pre>
<p>Exchange blocks are allowed inside uniform control flow:</p>
<pre><code class="language-c">for (int iter = 0; iter &lt; 1000; iter++) {  // Scalar bound
    exchange {
        n = news(NORTH, temp);             // All processors participate
    }
    temp = update(temp, n);
}
</code></pre>
<h3 id="divergent-control-flow">Divergent Control Flow</h3>
<p>Divergent control flow means processors take different paths. The condition is a pvar—different value on each processor.</p>
<p>StarC uses <code>where</code> for divergent control flow:</p>
<pre><code class="language-c">pvar&lt;int&gt; x;

where (x &gt; 100) {             // Some processors execute, others don&#39;t
    x = 0;                    // Only where condition is true
}
</code></pre>
<p>Each processor independently evaluates <code>x &gt; 100</code> and decides whether to execute the body.</p>
<p><strong><code>if</code> vs <code>where</code>:</strong></p>
<ul>
<li><code>if (scalar_condition)</code> — uniform, all processors same branch</li>
<li><code>where (pvar_condition)</code> — divergent, per-processor decision</li>
</ul>
<p>This distinction is enforced. If you write <code>if (pvar_condition)</code>, the preprocessor warns you. Use <code>where</code> to signal divergent intent.</p>
<p><strong>Exchange blocks are NOT allowed inside <code>where</code>:</strong></p>
<pre><code class="language-c">where (x &gt; 0) {
    exchange {                // ERROR: divergent exchange
        y = nbr(0, x);
    }
}
</code></pre>
<p>This is illegal because some processors would skip the exchange. The TDMA schedule requires all processors to participate—if half the processors don&#39;t transmit during their phase, communication breaks.</p>
<p><strong>Solution: make data conditional, not exchange:</strong></p>
<pre><code class="language-c">pvar&lt;int&gt; to_send = (x &gt; 0) ? x : 0;  // Conditional data
exchange {
    y = nbr(0, to_send);              // All processors participate
}
</code></pre>
<h3 id="nesting">Nesting</h3>
<p>Uniform inside uniform: fine.</p>
<pre><code class="language-c">for (int i = 0; i &lt; 10; i++) {
    if (i % 2 == 0) {
        // All processors, on even iterations
    }
}
</code></pre>
<p>Divergent inside divergent: fine.</p>
<pre><code class="language-c">where (x &gt; 0) {
    where (x &gt; 100) {
        x = 100;              // Only where x &gt; 100
    }
}
</code></pre>
<p>Divergent inside uniform: fine.</p>
<pre><code class="language-c">for (int i = 0; i &lt; 10; i++) {
    where (x &gt; i) {
        x = x - 1;            // Per-processor conditional
    }
}
</code></pre>
<p>Uniform with exchange inside divergent: <strong>not allowed</strong>.</p>
<pre><code class="language-c">where (x &gt; 0) {
    for (int i = 0; i &lt; 10; i++) {
        exchange { ... }      // ERROR: inside divergent
    }
}
</code></pre>
<h3 id="functions">Functions</h3>
<p>Functions can take pvar parameters and use <code>where</code>:</p>
<pre><code class="language-c">pvar&lt;float&gt; clamp(pvar&lt;float&gt; x, float lo, float hi) {
    pvar&lt;float&gt; result = x;
    where (x &lt; lo) { result = lo; }
    where (x &gt; hi) { result = hi; }
    return result;
}

pvar&lt;float&gt; data;
data = clamp(data, 0.0f, 1.0f);  // All processors call simultaneously
</code></pre>
<p><strong>Rules for functions:</strong></p>
<ul>
<li>All processors call the function together (SPMD)</li>
<li><code>where</code> inside functions works normally</li>
<li>No <code>exchange</code> blocks inside functions—move them to the caller</li>
</ul>
<p>The no-exchange rule keeps function semantics simple. A function is pure local computation. Communication happens at the call site.</p>
<hr>
<h2 id="chapter-5-communication">Chapter 5: Communication</h2>
<p>All communication happens inside <code>exchange</code> blocks. This chapter covers the exchange block mechanics and each communication primitive.</p>
<h3 id="exchange-blocks">Exchange Blocks</h3>
<p>An <code>exchange</code> block declares what communications are needed. It&#39;s not sequential code—it&#39;s a <strong>declaration</strong> that the runtime executes optimally.</p>
<pre><code class="language-c">exchange {
    a = nbr(0, x);
    b = nbr(5, y);
    total = reduce_sum(z);
}
</code></pre>
<p><strong>Snapshot semantics:</strong> All input values are captured at block entry. You cannot use the result of one exchange as input to another within the same block.</p>
<pre><code class="language-c">pvar&lt;int&gt; x = 5;
exchange {
    a = nbr(0, x);    // Captures x=5
    b = nbr(1, x);    // Also captures x=5, not &#39;a&#39;
}
// Now a and b are valid
</code></pre>
<p><strong>Rules:</strong></p>
<ol>
<li>Communication primitives may ONLY appear inside <code>exchange</code> blocks</li>
<li>No using results from the same block as inputs</li>
<li>No nested <code>exchange</code> blocks</li>
<li>No <code>exchange</code> inside <code>where</code> blocks</li>
<li>Scalar control flow (loops with scalar bounds) IS allowed</li>
</ol>
<p><strong>Scalar loops in exchange blocks:</strong></p>
<pre><code class="language-c">exchange {
    for (int d = 0; d &lt; 12; d++) {
        neighbors[d] = nbr(d, data);
    }
}
</code></pre>
<p>This is allowed because the loop counter is scalar—it&#39;s just syntactic sugar for 12 declarations. The rule is: <strong>scalar control flow that can be unrolled at compile time is allowed</strong>.</p>
<p><strong>Capacity limit:</strong> If declared exchanges exceed one superframe&#39;s capacity, the runtime aborts with an error. This is deliberate—automatic splitting would hide costs and make performance unpredictable. If you need more, use multiple exchange blocks.</p>
<h3 id="neighbor-exchange-nbr">Neighbor Exchange: <code>nbr()</code></h3>
<pre><code class="language-c">T nbr(int dim, T value)
</code></pre>
<p>Exchange <code>value</code> with your hypercube neighbor in dimension <code>dim</code> (0-11). Returns the neighbor&#39;s value.</p>
<pre><code class="language-c">exchange {
    pvar&lt;int&gt; n0 = nbr(0, data);   // Dimension 0 neighbor
    pvar&lt;int&gt; n5 = nbr(5, data);   // Dimension 5 neighbor
}
</code></pre>
<p>Your neighbor in dimension <code>dim</code> is the processor whose address differs from yours in bit <code>dim</code>. If you&#39;re processor 0b101010, your dimension-0 neighbor is 0b101011, your dimension-1 neighbor is 0b101000, etc.</p>
<p><strong>Cost:</strong> 2 phases per dimension (one each direction).</p>
<h3 id="grid-neighbors-news">Grid Neighbors: <code>news()</code></h3>
<pre><code class="language-c">T news(direction_t dir, T value)
</code></pre>
<p>Exchange with your grid neighbor. Directions: <code>NORTH</code>, <code>EAST</code>, <code>SOUTH</code>, <code>WEST</code>.</p>
<pre><code class="language-c">exchange {
    n = news(NORTH, temp);
    e = news(EAST, temp);
    s = news(SOUTH, temp);
    w = news(WEST, temp);
}
</code></pre>
<p><code>news()</code> is <code>nbr()</code> with automatic dimension selection. The runtime computes which dimension corresponds to each direction based on your grid position and the Gray code mapping.</p>
<p><strong>Edge behavior:</strong> The grid wraps toroidally. Row 0&#39;s NORTH neighbor is row 63. Column 63&#39;s EAST neighbor is column 0. Because of Gray code, edge wrapping is still a single-bit change—one hypercube hop.</p>
<p><strong>Cost:</strong> NORTH and SOUTH use row dimensions (6-11). EAST and WEST use column dimensions (0-5). These don&#39;t overlap, so four cardinal directions use <strong>8 phases</strong> (4 dimensions × 2 phases each).</p>
<h3 id="diagonal-neighbors">Diagonal Neighbors</h3>
<p>Diagonal neighbors (NE, NW, SE, SW) require two hops: one row dimension and one column dimension. Since exchange blocks can&#39;t use results as inputs within the same block, diagonals need <strong>two exchange blocks</strong>:</p>
<pre><code class="language-c">pvar&lt;int&gt; n, e, s, w;
pvar&lt;int&gt; ne, nw, se, sw;

// First: get cardinal neighbors
exchange {
    n = news(NORTH, cell);
    e = news(EAST, cell);
    s = news(SOUTH, cell);
    w = news(WEST, cell);
}

// Second: get diagonals via cardinals
exchange {
    ne = news(NORTH, e);  // My N neighbor&#39;s E = my NE
    nw = news(NORTH, w);  // My N neighbor&#39;s W = my NW
    se = news(SOUTH, e);  // My S neighbor&#39;s E = my SE
    sw = news(SOUTH, w);  // My S neighbor&#39;s W = my SW
}
</code></pre>
<p><strong>How this works:</strong> After the first exchange, I have my east neighbor&#39;s value in <code>e</code>. In the second exchange, <code>news(NORTH, e)</code> sends my <code>e</code> northward. I receive my north neighbor&#39;s <code>e</code>—which is their east neighbor&#39;s value. My north neighbor&#39;s east neighbor is my northeast neighbor.</p>
<p><strong>Cost:</strong> Two superframes for 8-neighbor stencils.</p>
<h3 id="reductions">Reductions</h3>
<pre><code class="language-c">T reduce_sum(pvar&lt;T&gt; value)
T reduce_min(pvar&lt;T&gt; value)
T reduce_max(pvar&lt;T&gt; value)
T reduce_and(pvar&lt;T&gt; value)
T reduce_or(pvar&lt;T&gt; value)
</code></pre>
<p>Combine values from all 4,096 processors into a single scalar. Every processor receives the same result.</p>
<pre><code class="language-c">exchange {
    int total = reduce_sum(local_count);
    int any_active = reduce_or(is_active);
}
// total and any_active are the same on all processors
</code></pre>
<p><strong>Implementation:</strong> Tree reduction over 12 dimensions, <strong>dimension 0 first, ascending</strong>. Each step exchanges with the neighbor in that dimension and combines. After 12 steps, everyone has the global result.</p>
<p>This is a multi-hop operation, but the path is fixed: dimension 0, then 1, then 2, ... then 11. It&#39;s a structured tree algorithm, not arbitrary routing.</p>
<p><strong>Floating-point determinism:</strong> The dimension ordering is guaranteed and the toolchain enforces <code>-fno-fast-math</code>. Identical inputs always produce identical outputs.</p>
<p><strong>Cost:</strong> 24 phases (one full superframe).</p>
<p><strong>Multiple reductions pipeline:</strong> Reductions in the same block share the same 24 phases, processing different data streams in parallel:</p>
<pre><code class="language-c">exchange {
    sum = reduce_sum(x);    // ┐
    max = reduce_max(y);    // ├─ All share one superframe
    count = reduce_sum(1);  // ┘
}
</code></pre>
<p><strong>Conditional participation:</strong> Processors that shouldn&#39;t contribute use identity values:</p>
<pre><code class="language-c">// Sum only positive values
pvar&lt;int&gt; contrib = (x &gt; 0) ? x : 0;  // Non-positive → 0
exchange {
    int sum = reduce_sum(contrib);    // Zeros don&#39;t affect sum
}
</code></pre>
<table>
<thead>
<tr>
<th>Operation</th>
<th>Identity Value</th>
</tr>
</thead>
<tbody><tr>
<td>sum</td>
<td>0</td>
</tr>
<tr>
<td>min</td>
<td>TYPE_MAX</td>
</tr>
<tr>
<td>max</td>
<td>TYPE_MIN</td>
</tr>
<tr>
<td>and</td>
<td>~0 (all 1s)</td>
</tr>
<tr>
<td>or</td>
<td>0</td>
</tr>
</tbody></table>
<h3 id="scans-prefix-operations">Scans (Prefix Operations)</h3>
<pre><code class="language-c">pvar&lt;T&gt; scan_sum(pvar&lt;T&gt; value)           // Exclusive
pvar&lt;T&gt; scan_min(pvar&lt;T&gt; value)           // Exclusive
pvar&lt;T&gt; scan_max(pvar&lt;T&gt; value)           // Exclusive
pvar&lt;T&gt; scan_sum_inclusive(pvar&lt;T&gt; value) // Inclusive
pvar&lt;T&gt; scan_min_inclusive(pvar&lt;T&gt; value) // Inclusive
pvar&lt;T&gt; scan_max_inclusive(pvar&lt;T&gt; value) // Inclusive
</code></pre>
<p>Prefix operations across all processors.</p>
<p><strong>Exclusive scan:</strong> Processor <em>i</em> receives combination of processors 0..<em>i</em>-1 (excluding self).</p>
<p><strong>Inclusive scan:</strong> Processor <em>i</em> receives combination of processors 0..<em>i</em> (including self).</p>
<pre><code class="language-c">pvar&lt;int&gt; x = 1;  // All processors have 1

exchange {
    pvar&lt;int&gt; excl = scan_sum(x);           // Exclusive
    pvar&lt;int&gt; incl = scan_sum_inclusive(x); // Inclusive
}

// Processor 0: excl=0, incl=1
// Processor 1: excl=1, incl=2
// Processor 2: excl=2, incl=3
// ...
// Processor 4095: excl=4095, incl=4096
</code></pre>
<p>Scans enable parallel compaction, load balancing, and many classic parallel algorithms.</p>
<p><strong>Cost:</strong> 24 phases.</p>
<h3 id="broadcast">Broadcast</h3>
<pre><code class="language-c">pvar&lt;T&gt; broadcast(int source_pid, T value)
</code></pre>
<p>Distribute one processor&#39;s value to all processors.</p>
<pre><code class="language-c">pvar&lt;float&gt; result;
if (pid() == 0) {
    result = special_computation();
}
exchange {
    pvar&lt;float&gt; everyone = broadcast(0, result);
}
// All processors now have processor 0&#39;s result
</code></pre>
<p><strong>Semantics:</strong> Only the source processor&#39;s <code>value</code> matters. Other processors&#39; values are undefined—don&#39;t rely on them.</p>
<p><strong>Implementation:</strong> Tree distribution over 12 dimensions.</p>
<p><strong>Cost:</strong> 24 phases.</p>
<h3 id="double-buffering">Double Buffering</h3>
<p>For high MCU utilization, overlap compute with communication:</p>
<pre><code class="language-c">exchange_async {
    neighbor = nbr(0, data);
}
// MCU computes while FPGA exchanges
next_data = expensive_compute(data);

exchange_wait();  // Block until exchange completes
// Now &#39;neighbor&#39; is valid
</code></pre>
<p><strong>Snapshot semantics:</strong> Values are captured when <code>exchange_async</code> begins. Modifying <code>data</code> during compute doesn&#39;t affect what gets sent—the snapshot was already taken.</p>
<p><strong>Rules:</strong></p>
<ul>
<li>Cannot read exchange results before <code>exchange_wait()</code></li>
<li>Cannot start new <code>exchange_async</code> before previous <code>exchange_wait()</code></li>
<li><code>exchange { }</code> is equivalent to <code>exchange_async { } exchange_wait();</code></li>
</ul>
<p><strong>Typical pattern:</strong></p>
<pre><code class="language-c">// Prime the pipeline
exchange {
    neighbor = nbr(0, data);
}

for (int i = 0; i &lt; 1000; i++) {
    exchange_async {
        neighbor = nbr(0, data);
    }
    
    // Compute using PREVIOUS neighbor (still valid from last iteration)
    next_data = compute(data, neighbor);
    
    exchange_wait();
    data = next_data;
}
</code></pre>
<hr>
<h2 id="chapter-6-host-io">Chapter 6: Host I/O</h2>
<p>Host communication uses the control tree, not the hypercube. This chapter covers loading data, storing results, and debugging output.</p>
<h3 id="bulk-data-transfer">Bulk Data Transfer</h3>
<pre><code class="language-c">void load_from_host(pvar&lt;T&gt; *dest, size_t count)
void store_to_host(pvar&lt;T&gt; *src, size_t count)
</code></pre>
<p>Load distributes data from the host to all processors. Store collects data from all processors to the host.</p>
<pre><code class="language-c">pvar&lt;float&gt; input;
load_from_host(&amp;input, 1);   // Each processor gets one float

// ... compute ...

pvar&lt;float&gt; result;
store_to_host(&amp;result, 1);   // Each processor sends one float
</code></pre>
<p>Data flows through the control tree: Host → Machine Controller → Plane Controllers → Slice Controllers → Nodes (and reverse for store).</p>
<p><strong>No 80-byte limit.</strong> The control tree is a separate network with different constraints. Large transfers are fine:</p>
<pre><code class="language-c">pvar&lt;float&gt; big_array[1000];
load_from_host(big_array, 1000);  // 4KB per processor—no problem
</code></pre>
<p><strong>Latency:</strong> Variable, depending on tree traversal and data size. Much slower than hypercube exchange for small data, but higher total bandwidth for bulk transfers.</p>
<h3 id="console-output">Console Output</h3>
<pre><code class="language-c">void host_printf(const char *fmt, ...)
</code></pre>
<p>Print to the host console. Only processor 0 should call this—other processors&#39; output is discarded.</p>
<pre><code class="language-c">if (pid() == 0) {
    host_printf(&quot;Starting computation\n&quot;);
}

// ... compute and exchange ...

if (pid() == 0) {
    int max = ...;  // result from reduction
    host_printf(&quot;Maximum value: %d\n&quot;, max);
}
</code></pre>
<h3 id="led-control">LED Control</h3>
<pre><code class="language-c">void led_set(uint8_t brightness)   // 0 = off, 255 = full
uint8_t led_get(void)              // Read current value
</code></pre>
<p>Set this processor&#39;s LED brightness. Updates flow through the control tree to the LED drivers.</p>
<pre><code class="language-c">// Visualize temperature
led_set((uint8_t)(temperature * 255.0f));

// Binary visualization
led_set(active ? 255 : 0);
</code></pre>
<p>LED operations are local—no <code>exchange</code> block needed. All 4,096 processors can set their LEDs simultaneously.</p>
<p>The LED array is a debugging primitive. When something goes wrong, the pattern tells you which processors are affected, which dimensions failed, where data is stuck.</p>
<div class="starc-part-header">
  <img src="/img/logo2.svg" alt="StarC Logo">
  <h1 id="part-iii-programming">Part III: Programming</h1>
</div>

<h2 id="chapter-7-patterns">Chapter 7: Patterns</h2>
<p>The following goes through examples from the StarC Playground, demonstrating the why and how everything in StarC works. Topics covered for each example:</p>
<ul>
<li>Dimension Walk - Direct hypercube addressing (<code>coord()</code>, <code>nbr()</code> on all 12 dimensions)</li>
<li>Bitonic Sort - Topology-aware algorithm (dimension = log₂, hypercube structure dictates algorithm)</li>
<li>Heat Equation - Stencil operations (<code>news()</code>), global convergence detection (<code>reduce_max()</code>), conditional participation with identity values</li>
<li>Global Statistics - Pipelined reductions (multiple reduce_* in single exchange block share superframe bandwidth)</li>
<li>Parallel Prefix - Exclusive vs. inclusive scans (<code>scan_sum()</code> vs <code>scan_sum_inclusive()</code>)</li>
<li>Stream Compaction - Practical application of prefix sum (computing destination addresses)</li>
<li>NEWS Blur - Basic 4-neighbor stencil, grid topology (<code>news()</code>)</li>
<li>Conway&#39;s Game of Life - Complex stencil (8 neighbors via two exchange blocks for diagonals)</li>
<li>Double-Buffered Stencil - Asynchronous communication (exchange_async/exchange_wait) for overlapping compute and communication</li>
<li>Random and Pleasing (LFSR) - Embarrassingly parallel computation (replicated scalar state, zero communication, independent per-processor computation)</li>
</ul>
<p>These examples provide enough context to StarC that you should be able to understand the language after following these examples. </p>
<p>If you&#39;d like to just <em>run</em> these examples, look at the saved examples on the StarC Playground.</p>
<h3 id="dimension-walk">Dimension Walk</h3>
<p>Pure hypercube. Uses <code>coord(dim)</code>, <code>nbr()</code> across all 12 dimensions.</p>
<p><img src="https://bbenchoff.github.io/images/StarC/DimensionWalk.gif" alt="Animated gif of the Dimension Walk"></p>

            <div class="code-block-wrapper collapsible">
                <div class="code-block-header">
                    <span class="code-block-title">Code Example</span>
                    <span class="code-block-toggle">Show Code</span>
                </div>
                <div class="code-block-content">
                    <pre><code class="language-c">// Dimension Walk - Hamiltonian path through 12D hypercube
// Uses coord() to build position from dimension bits
// Uses nbr() to highlight the 12-dimensional neighborhood
// Gray code ensures each step moves to exactly 1 neighbor

void main() {
  // Build my position from individual dimension coordinates
  pvar&lt;int&gt; c0 = coord(0);
  pvar&lt;int&gt; c1 = coord(1);
  pvar&lt;int&gt; c2 = coord(2);
  pvar&lt;int&gt; c3 = coord(3);
  pvar&lt;int&gt; c4 = coord(4);
  pvar&lt;int&gt; c5 = coord(5);
  pvar&lt;int&gt; c6 = coord(6);
  pvar&lt;int&gt; c7 = coord(7);
  pvar&lt;int&gt; c8 = coord(8);
  pvar&lt;int&gt; c9 = coord(9);
  pvar&lt;int&gt; c10 = coord(10);
  pvar&lt;int&gt; c11 = coord(11);

  // My 12-bit position: c11 c10 c9 ... c2 c1 c0
  pvar&lt;int&gt; my_position = (c11 &lt;&lt; 11) | (c10 &lt;&lt; 10) | (c9 &lt;&lt; 9) | (c8 &lt;&lt; 8) |
                          (c7 &lt;&lt; 7) | (c6 &lt;&lt; 6) | (c5 &lt;&lt; 5) | (c4 &lt;&lt; 4) |
                          (c3 &lt;&lt; 3) | (c2 &lt;&lt; 2) | (c1 &lt;&lt; 1) | c0;

  int counter = 0;

  for (;;) {
    // Convert counter to Gray code (Hamiltonian path property)
    int gray = counter ^ (counter &gt;&gt; 1);

    // Am I the current position?
    pvar&lt;int&gt; lit = 0;
    where (my_position == gray) {
      lit = 255;  // Bright: current position
    }

    // Use nbr() to highlight my 12 neighbors in the hypercube
    exchange {
      pvar&lt;int&gt; n0 = nbr(0, lit);
      pvar&lt;int&gt; n1 = nbr(1, lit);
      pvar&lt;int&gt; n2 = nbr(2, lit);
      pvar&lt;int&gt; n3 = nbr(3, lit);
      pvar&lt;int&gt; n4 = nbr(4, lit);
      pvar&lt;int&gt; n5 = nbr(5, lit);
      pvar&lt;int&gt; n6 = nbr(6, lit);
      pvar&lt;int&gt; n7 = nbr(7, lit);
      pvar&lt;int&gt; n8 = nbr(8, lit);
      pvar&lt;int&gt; n9 = nbr(9, lit);
      pvar&lt;int&gt; n10 = nbr(10, lit);
      pvar&lt;int&gt; n11 = nbr(11, lit);

      // If any neighbor is bright, I&#39;m dim (shows hypercube connectivity)
      pvar&lt;int&gt; any_neighbor = n0 | n1 | n2 | n3 | n4 | n5 | n6 | n7 | n8 | n9 | n10 | n11;
      where (any_neighbor &gt; 0 &amp;&amp; lit == 0) {
        lit = 64;  // Dim: neighbor of current position
      }
    }

    led_set(lit);

    // Advance to next Gray code position
    counter = (counter + 1) &amp; 4095;
    barrier();
  }
}
</code></pre>
                </div>
            </div>
        


<h3 id="bitonic-sort">Bitonic Sort</h3>
<p>The canonical hypercube algorithm. <code>nbr(log₂(j), key)</code>. Proves topology = algorithm.</p>
<h3 id="heat-equation">Heat Equation</h3>
<p>Stencil + convergence. <code>news()</code> for neighbors, <code>reduce_max()</code> for termination. Shows conditional participation with identity values.</p>
<h3 id="global-statistics">Global Statistics</h3>
<p>Pipelined reductions. Multiple <code>reduce_*</code> in one exchange block. Shows they share the superframe.</p>
<h3 id="parallel-prefix-exclusive-and-inclusive">Parallel Prefix (Exclusive and Inclusive)</h3>
<p><code>scan_sum()</code> and <code>scan_sum_inclusive()</code>. Shows the difference.</p>
<h3 id="stream-compaction">Stream Compaction</h3>
<p>Application of prefix sum. <code>scan_sum()</code> → destination addresses.</p>
<h3 id="news-blur">NEWS Blur</h3>
<p>4-neighbor stencil. Clean <code>news()</code> usage.</p>

            <div class="code-block-wrapper collapsible">
                <div class="code-block-header">
                    <span class="code-block-title">Code Example</span>
                    <span class="code-block-toggle">Show Code</span>
                </div>
                <div class="code-block-content">
                    <pre><code class="language-c">// 2D Gaussian blur using NEWS communication
// Each pixel averages with its 4 neighbors

void main() {
  pvar&lt;int&gt; x = pid() % 64;
  pvar&lt;int&gt; y = pid() / 64;

  // Initialize with a simple pattern
  pvar&lt;int&gt; value = 0;
  where (x &gt; 20 &amp;&amp; x &lt; 44 &amp;&amp; y &gt; 20 &amp;&amp; y &lt; 44) {
    value = 255;
  }

  // Declare neighbor variables outside the loop
  pvar&lt;int&gt; north;
  pvar&lt;int&gt; south;
  pvar&lt;int&gt; east;
  pvar&lt;int&gt; west;

  for (;;) {
    // All communication must happen in an exchange block
    exchange {
      north = news(NORTH, value);
      south = news(SOUTH, value);
      east = news(EAST, value);
      west = news(WEST, value);
    }

    // 5-point stencil: average with 4 neighbors
    pvar&lt;int&gt; sum = value * 2 + north + south + east + west;
    value = sum / 6;

    led_set(value);

    barrier();
  }
}
</code></pre>
                </div>
            </div>
        

<h3 id="conway39s-game-of-life">Conway&#39;s Game of Life</h3>
<p>Because of course a gigantic LED array needs to run Game of Life. This example uses two iterations of the <code>news()</code> grid to create a stencil with eight neighbors.</p>
<p><img src="https://bbenchoff.github.io/images/StarC/Conway.gif" alt="Animated gif of Conway&#39;s Game of Life"></p>

            <div class="code-block-wrapper collapsible">
                <div class="code-block-header">
                    <span class="code-block-title">Code Example</span>
                    <span class="code-block-toggle">Show Code</span>
                </div>
                <div class="code-block-content">
                    <pre><code class="language-c">// Conway&#39;s Game of Life using NEWS communication
// Classic cellular automaton with multiple patterns

void main() {
  pvar&lt;int&gt; x = pid() % 64;
  pvar&lt;int&gt; y = pid() / 64;

  pvar&lt;int&gt; alive = 0;

  // Acorn pattern at (10, 10)
  where ((x == 11 &amp;&amp; y == 10) || (x == 13 &amp;&amp; y == 11) ||
         (x == 10 &amp;&amp; y == 12) || (x == 11 &amp;&amp; y == 12) ||
         (x == 14 &amp;&amp; y == 12) || (x == 15 &amp;&amp; y == 12) || 
         (x == 16 &amp;&amp; y == 12)) {
    alive = 1;
  }

  // R-pentomino at (40, 20)
  where ((x == 41 &amp;&amp; y == 20) || (x == 42 &amp;&amp; y == 20) ||
         (x == 40 &amp;&amp; y == 21) || (x == 41 &amp;&amp; y == 21) ||
         (x == 41 &amp;&amp; y == 22)) {
    alive = 1;
  }

  // Glider at (50, 50)
  where ((x == 50 &amp;&amp; y == 50) || (x == 51 &amp;&amp; y == 51) ||
         (x == 49 &amp;&amp; y == 52) || (x == 50 &amp;&amp; y == 52) || 
         (x == 51 &amp;&amp; y == 52)) {
    alive = 1;
  }

  // Lightweight spaceship (LWSS) at (5, 40)
  where ((x == 6 &amp;&amp; y == 40) || (x == 7 &amp;&amp; y == 40) || 
         (x == 8 &amp;&amp; y == 40) || (x == 9 &amp;&amp; y == 40) ||
         (x == 5 &amp;&amp; y == 41) || (x == 10 &amp;&amp; y == 41) ||
         (x == 10 &amp;&amp; y == 42) || (x == 5 &amp;&amp; y == 43) ||
         (x == 9 &amp;&amp; y == 43)) {
    alive = 1;
  }

  // Pulsar (oscillator) at (30, 35) - period 3
  where ((x == 28 &amp;&amp; y == 29) || (x == 29 &amp;&amp; y == 29) || 
         (x == 30 &amp;&amp; y == 29) || (x == 34 &amp;&amp; y == 29) ||
         (x == 35 &amp;&amp; y == 29) || (x == 36 &amp;&amp; y == 29)) {
    alive = 1;
  }
  where ((x == 26 &amp;&amp; y == 31) || (x == 31 &amp;&amp; y == 31) || 
         (x == 33 &amp;&amp; y == 31) || (x == 38 &amp;&amp; y == 31)) {
    alive = 1;
  }
  where ((x == 26 &amp;&amp; y == 32) || (x == 31 &amp;&amp; y == 32) ||
         (x == 33 &amp;&amp; y == 32) || (x == 38 &amp;&amp; y == 32)) {
    alive = 1;
  }
  where ((x == 26 &amp;&amp; y == 33) || (x == 31 &amp;&amp; y == 33) ||
         (x == 33 &amp;&amp; y == 33) || (x == 38 &amp;&amp; y == 33)) {
    alive = 1;
  }
  where ((x == 28 &amp;&amp; y == 34) || (x == 29 &amp;&amp; y == 34) ||
         (x == 30 &amp;&amp; y == 34) || (x == 34 &amp;&amp; y == 34) ||
         (x == 35 &amp;&amp; y == 34) || (x == 36 &amp;&amp; y == 34)) {
    alive = 1;
  }
  where ((x == 28 &amp;&amp; y == 39) || (x == 29 &amp;&amp; y == 39) ||
         (x == 30 &amp;&amp; y == 39) || (x == 34 &amp;&amp; y == 39) ||
         (x == 35 &amp;&amp; y == 39) || (x == 36 &amp;&amp; y == 39)) {
    alive = 1;
  }
  where ((x == 26 &amp;&amp; y == 40) || (x == 31 &amp;&amp; y == 40) ||
         (x == 33 &amp;&amp; y == 40) || (x == 38 &amp;&amp; y == 40)) {
    alive = 1;
  }
  where ((x == 26 &amp;&amp; y == 41) || (x == 31 &amp;&amp; y == 41) ||
         (x == 33 &amp;&amp; y == 41) || (x == 38 &amp;&amp; y == 41)) {
    alive = 1;
  }
  where ((x == 26 &amp;&amp; y == 42) || (x == 31 &amp;&amp; y == 42) ||
         (x == 33 &amp;&amp; y == 42) || (x == 38 &amp;&amp; y == 42)) {
    alive = 1;
  }
  where ((x == 28 &amp;&amp; y == 44) || (x == 29 &amp;&amp; y == 44) ||
         (x == 30 &amp;&amp; y == 44) || (x == 34 &amp;&amp; y == 44) ||
         (x == 35 &amp;&amp; y == 44) || (x == 36 &amp;&amp; y == 44)) {
    alive = 1;
  }

  // Declare neighbor variables outside the loop
  pvar&lt;int&gt; n;
  pvar&lt;int&gt; s;
  pvar&lt;int&gt; e;
  pvar&lt;int&gt; w;
  pvar&lt;int&gt; ne;
  pvar&lt;int&gt; nw;
  pvar&lt;int&gt; se;
  pvar&lt;int&gt; sw;

  for (;;) {

    // Exchange 1: Get cardinal neighbors
    exchange {
      n = news(NORTH, alive);
      s = news(SOUTH, alive);
      e = news(EAST, alive);
      w = news(WEST, alive);
    }

    // Exchange 2: Get diagonal neighbors via cardinals
    // My north neighbor&#39;s east = my northeast
    exchange {
      ne = news(NORTH, e);
      nw = news(NORTH, w);
      se = news(SOUTH, e);
      sw = news(SOUTH, w);
    }

    pvar&lt;int&gt; neighbors = n + s + e + w + ne + nw + se + sw;

    // Conway&#39;s rules (optimized):
    // Live cell: survives if 2-3 neighbors
    // Dead cell: born if exactly 3 neighbors
    pvar&lt;int&gt; survive = (alive == 1) &amp;&amp; (neighbors == 2 || neighbors == 3);
    pvar&lt;int&gt; born = (alive == 0) &amp;&amp; (neighbors == 3);
    alive = survive || born;

    // Display: compute LED value directly (faster than where blocks)
    pvar&lt;int&gt; brightness = alive * 255;
    led_set(brightness);

    barrier();
  }
}
</code></pre>
                </div>
            </div>
        

<h3 id="double-buffered-stencil">Double-Buffered Stencil</h3>
<p><code>exchange_async</code> / <code>exchange_wait</code>. MCU utilization.</p>
<h3 id="random-and-pleasing">Random and Pleasing</h3>
<p>This is the single reason you&#39;ve ever seen a Connection Machine in print or media. The original CM-1, CM-2, and CM-5 all had a, &quot;random LFSR, scrolling randomly&quot; setting for the front lights. You can see it in Jurassic Park, and it&#39;s what the MoMA runs when they pull their CM-1 out of storage. While what these lights <em>looked like</em> is well documented, the actual code that produced this pattern is not.</p>
<p>For my machine, I break up the 64x64 pixel panel into 1x16 &#39;windows&#39;. These windows either scroll left or right. The content of these windows is determined by an LFSR -- a pseudo-random bit generator. A bit is generated from the LFSR, and pushed into the &#39;window&#39;. Another bit is generated by the LFSR (either 1 or 0), and the existing bit in each window is pushed to the left or right. The eventual result is a &quot;shimmer&quot; of LEDs. It <em>looks</em> like the computer is doing something important.</p>
<p>This Random and Pleasing mode is enough like the original mode found in Connection Machines that I&#39;ll call it a clone. It&#39;s not a direct copy, but then again the layout of the front panel isn&#39;t either.</p>
<p><img src="https://bbenchoff.github.io/images/StarC/RandomAndPleasing.gif" alt="Animated gif of the random and pleasing mode"></p>
<p><strong>How this works</strong></p>
<p>First, we define 8 LFSRs shared across all the processors. Then, we create some &#39;bookkeeping&#39; variables per processor. These bookkeeping variables define the <code>x</code> and <code>y</code> locations on the display. The display is split up into four &#39;columns&#39; consisting of 1x16 pixel &#39;windows&#39;, so we declare those as well.</p>
<pre><code class="language-c">  int lfsr[8];
  lfsr[0] = 0xACE1BEEF;
  ...
  lfsr[7] = 0xBADC0FFE;

  // Per-processor state: figure out my role
  pvar&lt;int&gt; x = pid() % 64;
  pvar&lt;int&gt; y = pid() / 64;
  pvar&lt;int&gt; col = x / 16;           // Column (0-3)
  pvar&lt;int&gt; pixel_in_col = x % 16;  // Pixel within window (0-15)
  pvar&lt;int&gt; segment_id = y * 4 + col;  // Window ID (0-255)
</code></pre>
<p>Next, we assign each window a unique LFSR bit. Each window will scroll randomly left or right, so we create the direction with some bitshift trickery:</p>
<pre><code class="language-c">  // Assign each window a unique LFSR bit (8 LFSRs × 32 bits = 256)
  pvar&lt;int&gt; permuted = (segment_id * 131 + 73) &amp; 0xFF;
  pvar&lt;int&gt; my_lfsr_idx = permuted / 32;  // Which LFSR (0-7)
  pvar&lt;int&gt; my_bit_pos = permuted % 32;   // Which bit (0-31)

  // Pseudo-random scroll direction per window
  pvar&lt;int&gt; my_direction = ((segment_id * 179 + 41) &gt;&gt; 3) &amp; 1;
</code></pre>
<p>Now comes the main loop, and this is where StarC reveals its elegance. The infinite loop steps all 8 LFSRs using a plain C for-loop—this executes once per frame, not per processor. Each LFSR advances using Galois LFSR logic with the primitive polynomial x³² + x³¹ + x²⁹ + x¹ + 1:</p>
<pre><code class="language-c">    for (int i = 0; i &lt; 8; i++) {
      int lsb = lfsr[i] &amp; 1;
      lfsr[i] = (lfsr[i] &gt;&gt; 1) ^ ((-lsb) &amp; 0xA0000002);
    }
</code></pre>
<p>Then the magic happens: each of the 4096 processors simultaneously reads from the scalar LFSR array using its own index: lfsr[my_lfsr_idx]. This single line demonstrates massively parallel array access—256 different windows extracting 256 different bits from 8 LFSRs, all at once:</p>
<pre><code class="language-c">pvar&lt;int&gt; new_bit = (lfsr[my_lfsr_idx] &gt;&gt; my_bit_pos) &amp; 1;
</code></pre>
<p>Each processor maintains its own 16-bit scroll buffer. The where() blocks handle directional scrolling—processors with my_direction == 0 shift right (pushing new bits from the left), while processors with my_direction == 1 shift left. Notice there&#39;s zero communication between processors; this is embarrassingly parallel:</p>
<pre><code class="language-c">    where (my_direction == 0) {
      scroll_buffer = (scroll_buffer &gt;&gt; 1) | (new_bit &lt;&lt; 15);
    }
    where (my_direction == 1) {
      scroll_buffer = (scroll_buffer &lt;&lt; 1) | new_bit;
    }
</code></pre>
<p>Finally, each processor extracts its display bit from its scroll buffer based on its position within the window, and sets its LED intensity. The barrier() synchronizes all processors before the next frame:</p>
<pre><code class="language-c">    pvar&lt;int&gt; display_bit = (scroll_buffer &gt;&gt; pixel_in_col) &amp; 1;
    led_set(display_bit * 255);
    barrier();
</code></pre>
<p>The result is 256 independent windows, each scrolling its own LFSR-generated pattern in its own direction, creating the &quot;thinking computer&quot; shimmer. This is StarC&#39;s design philosophy in action: it&#39;s just C until it isn&#39;t. Plain for-loops stepping LFSRs in scalar context, then massively parallel array indexing when you need it.</p>
<p><strong>Code Listing</strong></p>

            <div class="code-block-wrapper collapsible">
                <div class="code-block-header">
                    <span class="code-block-title">Code Example</span>
                    <span class="code-block-toggle">Show Code</span>
                </div>
                <div class="code-block-content">
                    <pre><code class="language-c">// LFSR Scrolling Columns - Embarrassingly Parallel!
// 64 rows × 4 columns = 256 independent 16-pixel-wide windows
// Each window displays a 16-bit LFSR scroll buffer, scrolling left/right
// Based on real hardware implementation (animations.h)

void main() {
  // Scalar array: 8 LFSRs shared across all processors
  // Polynomial: x^32 + x^31 + x^29 + x^1 + 1 → mask 0xA0000002
  int lfsr[8];
  lfsr[0] = 0xACE1BEEF;
  lfsr[1] = 0xCAFEDEAD;
  lfsr[2] = 0x12345678;
  lfsr[3] = 0x9ABCDEF0;
  lfsr[4] = 0xFEDCBA98;
  lfsr[5] = 0x76543210;
  lfsr[6] = 0xDEADBEEF;
  lfsr[7] = 0xBADC0FFE;

  // Per-processor state: figure out my role
  pvar&lt;int&gt; x = pid() % 64;
  pvar&lt;int&gt; y = pid() / 64;
  pvar&lt;int&gt; col = x / 16;           // Column (0-3)
  pvar&lt;int&gt; pixel_in_col = x % 16;  // Pixel within window (0-15)
  pvar&lt;int&gt; segment_id = y * 4 + col;  // Window ID (0-255)

  // Assign each window a unique LFSR bit (8 LFSRs × 32 bits = 256)
  pvar&lt;int&gt; permuted = (segment_id * 131 + 73) &amp; 0xFF;
  pvar&lt;int&gt; my_lfsr_idx = permuted / 32;  // Which LFSR (0-7)
  pvar&lt;int&gt; my_bit_pos = permuted % 32;   // Which bit (0-31)

  // Pseudo-random scroll direction per window
  pvar&lt;int&gt; my_direction = ((segment_id * 179 + 41) &gt;&gt; 3) &amp; 1;

  // Each window has a 16-bit scroll buffer
  pvar&lt;int&gt; scroll_buffer = 0;

  for (;;) {
    // Step all 8 LFSRs (plain C loop)
    for (int i = 0; i &lt; 8; i++) {
      int lsb = lfsr[i] &amp; 1;
      lfsr[i] = (lfsr[i] &gt;&gt; 1) ^ ((-lsb) &amp; 0xA0000002);
    }

    // Extract my assigned bit - index scalar array with pvar!
    pvar&lt;int&gt; new_bit = (lfsr[my_lfsr_idx] &gt;&gt; my_bit_pos) &amp; 1;

    // Shift into scroll buffer (direction depends on my_direction)
    where (my_direction == 0) {
      scroll_buffer = (scroll_buffer &gt;&gt; 1) | (new_bit &lt;&lt; 15);
    }
    where (my_direction == 1) {
      scroll_buffer = (scroll_buffer &lt;&lt; 1) | new_bit;
    }

    // Display my bit from the scroll buffer
    pvar&lt;int&gt; display_bit = (scroll_buffer &gt;&gt; pixel_in_col) &amp; 1;
    led_set(display_bit * 255);

    barrier();
  }
}
</code></pre>
                </div>
            </div>
        


<hr>
<h2 id="chapter-8-performance">Chapter 8: Performance</h2>
<p>This chapter explains the cost model and how to reason about performance.</p>
<h3 id="timing-model">Timing Model</h3>
<p>At 1 kHz phase clock:</p>
<table>
<thead>
<tr>
<th>Unit</th>
<th>Duration</th>
</tr>
</thead>
<tbody><tr>
<td>Phase</td>
<td>1 ms</td>
</tr>
<tr>
<td>Superframe (24 phases)</td>
<td>24 ms</td>
</tr>
</tbody></table>
<p><strong>Operation costs:</strong></p>
<table>
<thead>
<tr>
<th>Operation</th>
<th>Phases</th>
<th>Time</th>
</tr>
</thead>
<tbody><tr>
<td><code>nbr()</code> — one dimension</td>
<td>2</td>
<td>2 ms</td>
</tr>
<tr>
<td><code>nbr()</code> — all 12 dimensions</td>
<td>24</td>
<td>24 ms</td>
</tr>
<tr>
<td><code>news()</code> — 4 cardinal directions</td>
<td>8</td>
<td>8 ms</td>
</tr>
<tr>
<td><code>reduce_*()</code> — one or more</td>
<td>24</td>
<td>24 ms</td>
</tr>
<tr>
<td><code>scan_*()</code></td>
<td>24</td>
<td>24 ms</td>
</tr>
<tr>
<td><code>broadcast()</code></td>
<td>24</td>
<td>24 ms</td>
</tr>
</tbody></table>
<h3 id="exchange-scheduling">Exchange Scheduling</h3>
<p>The runtime schedules exchanges to minimize superframe usage.</p>
<p><strong>What fits in one superframe:</strong></p>
<ul>
<li>Up to 12 <code>nbr()</code> calls on <strong>different</strong> dimensions</li>
<li>AND/OR multiple pipelined reductions</li>
<li>AND/OR one scan</li>
<li>AND/OR one broadcast</li>
</ul>
<p><strong>What exceeds capacity (runtime error):</strong></p>
<ul>
<li>More than ~160 bytes total on a single dimension</li>
<li>Scan + reduction in same block (both need the full tree)</li>
<li>Too many exchanges overall</li>
</ul>
<p><strong>Examples:</strong></p>
<pre><code class="language-c">// OK: 12 different dimensions
exchange {
    for (int d = 0; d &lt; 12; d++) {
        neighbors[d] = nbr(d, data);
    }
}

// OK: multiple reductions (pipelined)
exchange {
    sum = reduce_sum(x);
    max = reduce_max(x);
    min = reduce_min(x);
}

// ERROR: reduction + scan both need full tree
exchange {
    total = reduce_sum(x);
    prefix = scan_sum(y);   // Can&#39;t share with reduction
}

// OK: separate blocks
exchange { total = reduce_sum(x); }
exchange { prefix = scan_sum(y); }
</code></pre>
<h3 id="automatic-reordering">Automatic Reordering</h3>
<p>The runtime reorders <code>nbr()</code> calls by dimension for optimal phase usage:</p>
<pre><code class="language-c">exchange {
    d11 = nbr(11, x);  // Declared first
    d0 = nbr(0, y);    // Declared second  
    d5 = nbr(5, z);    // Declared third
}
// Executes: d0 (phases 0-1), d5 (phases 10-11), d11 (phases 22-23)
</code></pre>
<p>You don&#39;t need to think about phase ordering—just declare what you need.</p>
<h3 id="bandwidth">Bandwidth</h3>
<table>
<thead>
<tr>
<th>Path</th>
<th>Payload</th>
<th>Bandwidth</th>
</tr>
</thead>
<tbody><tr>
<td>Hypercube (per dimension)</td>
<td>80 B / 2 ms</td>
<td>40 KB/s</td>
</tr>
<tr>
<td>Hypercube (all dimensions)</td>
<td>960 B / 24 ms</td>
<td>40 KB/s</td>
</tr>
<tr>
<td>Control tree (bulk)</td>
<td>Unlimited</td>
<td>~1 MB/s</td>
</tr>
</tbody></table>
<p>The hypercube is latency-optimized: small payloads, fast phases, deterministic timing. Use it for algorithm communication.</p>
<p>The control tree is bandwidth-optimized: large transfers, variable latency. Use it for bulk I/O.</p>
<h3 id="mcu-utilization">MCU Utilization</h3>
<p><strong>Without double buffering:</strong></p>
<p>During an exchange, the MCU waits. At 133 MHz, a 24 ms superframe wastes 3.2 million cycles.</p>
<p><strong>With double buffering:</strong></p>
<p>The MCU computes iteration N+1 while the FPGA exchanges iteration N. Utilization depends on the ratio:</p>
<ul>
<li>If compute &gt; exchange: MCU-bound, utilization ≈ 100%</li>
<li>If compute &lt; exchange: exchange-bound, utilization ≈ compute/exchange</li>
<li>If compute ≈ exchange: optimal overlap, utilization ≈ 100%</li>
</ul>
<h3 id="phase-rate-trade-offs">Phase Rate Trade-offs</h3>
<p>The phase rate is configurable:</p>
<table>
<thead>
<tr>
<th>Rate</th>
<th>Superframe</th>
<th>Payload/Phase</th>
<th>Use Case</th>
</tr>
</thead>
<tbody><tr>
<td>100 Hz</td>
<td>240 ms</td>
<td>800 bytes</td>
<td>Debug, huge payloads</td>
</tr>
<tr>
<td>1 kHz</td>
<td>24 ms</td>
<td>80 bytes</td>
<td>Default, balanced</td>
</tr>
<tr>
<td>10 kHz</td>
<td>2.4 ms</td>
<td>8 bytes</td>
<td>Low latency, small data</td>
</tr>
</tbody></table>
<p>Slower rates give more payload per phase. Faster rates give lower latency but smaller payloads.</p>
<h3 id="iteration-rates">Iteration Rates</h3>
<p>Typical workloads at 1 kHz:</p>
<table>
<thead>
<tr>
<th>Workload</th>
<th>Exchange Time</th>
<th>Iter/Sec</th>
</tr>
</thead>
<tbody><tr>
<td>4-neighbor stencil</td>
<td>~8 ms</td>
<td>~100</td>
</tr>
<tr>
<td>8-neighbor stencil</td>
<td>~48 ms</td>
<td>~20</td>
</tr>
<tr>
<td>Stencil + reduction</td>
<td>~32 ms</td>
<td>~30</td>
</tr>
<tr>
<td>Single bitonic step</td>
<td>~2 ms</td>
<td>~500</td>
</tr>
</tbody></table>
<div class="starc-part-header">
  <img src="/img/logo2.svg" alt="StarC Logo">
  <h1 id="part-iv-implementation">Part IV: Implementation</h1>
</div>

<h2 id="chapter-9-toolchain">Chapter 9: Toolchain</h2>
<p>This chapter describes how StarC source code becomes executable firmware.</p>
<h3 id="build-pipeline">Build Pipeline</h3>
<pre><code>algorithm.starc
      ↓
  starc_pp.py (Python preprocessor)
      ↓
algorithm.c (plain C with runtime calls)
      ↓
  gcc / riscv-gcc
      ↓
algorithm.elf (executable)
</code></pre>
<p>StarC is not a compiler. It&#39;s a preprocessor that rewrites StarC syntax into C, then a standard C compiler produces the binary.</p>
<h3 id="preprocessor-transformations">Preprocessor Transformations</h3>
<p>The preprocessor tokenizes the source (not regex—proper tokenization) and rewrites StarC constructs:</p>
<table>
<thead>
<tr>
<th>StarC</th>
<th>Generated C</th>
</tr>
</thead>
<tbody><tr>
<td><code>pvar&lt;T&gt; x;</code></td>
<td><code>T x;</code></td>
</tr>
<tr>
<td><code>where (c) { }</code></td>
<td><code>if (c) { }</code></td>
</tr>
<tr>
<td><code>if (c) { }</code></td>
<td><code>if (c) { }</code> (validated: c must be scalar)</td>
</tr>
<tr>
<td><code>exchange { ... }</code></td>
<td><code>star_ex_begin(); ... star_ex_execute();</code></td>
</tr>
<tr>
<td><code>exchange_async { ... }</code></td>
<td><code>star_ex_begin(); ... star_ex_start();</code></td>
</tr>
<tr>
<td><code>exchange_wait()</code></td>
<td><code>star_ex_wait();</code></td>
</tr>
<tr>
<td><code>nbr(d, v)</code></td>
<td><code>star_ex_nbr(d, &amp;r, &amp;v, sizeof(v))</code></td>
</tr>
<tr>
<td><code>reduce_sum(v)</code></td>
<td><code>star_ex_reduce(SUM, &amp;r, &amp;v, sizeof(v))</code></td>
</tr>
<tr>
<td><code>scan_sum(v)</code></td>
<td><code>star_ex_scan(SUM, EXCL, &amp;r, &amp;v, sizeof(v))</code></td>
</tr>
<tr>
<td><code>news(NORTH, v)</code></td>
<td><code>star_ex_news(NORTH, &amp;r, &amp;v, sizeof(v))</code></td>
</tr>
<tr>
<td><code>pid()</code></td>
<td><code>star_pid()</code></td>
</tr>
<tr>
<td><code>grid_row()</code></td>
<td><code>star_grid_row()</code></td>
</tr>
<tr>
<td><code>grid_col()</code></td>
<td><code>star_grid_col()</code></td>
</tr>
</tbody></table>
<h3 id="preprocessor-diagnostics">Preprocessor Diagnostics</h3>
<p>The preprocessor validates StarC rules and emits warnings/errors:</p>
<ul>
<li><strong>Warning:</strong> <code>if</code> condition appears to involve a pvar (should use <code>where</code>)</li>
<li><strong>Error:</strong> <code>exchange</code> block inside <code>where</code> block</li>
<li><strong>Error:</strong> Exchange result used as input within same block</li>
<li><strong>Error:</strong> Nested <code>exchange</code> blocks</li>
<li><strong>Error:</strong> Communication primitive outside <code>exchange</code> block</li>
<li><strong>Error:</strong> Cannot assign pvar to scalar variable<ul>
<li>Catches <code>scalar = pvar_value</code> assignments</li>
<li>This is a type error that breaks SPMD semantics</li>
</ul>
</li>
<li><strong>Error:</strong> Cannot mutate scalar variable inside where() block<ul>
<li>Catches <code>where (cond) { scalar = scalar + 1; }</code></li>
<li>Prevents the &quot;4096 decrements per frame&quot; bug class</li>
</ul>
</li>
<li><strong>Error:</strong> Array index out of bounds<ul>
<li>Runtime bounds checking for scalar arrays</li>
<li><code>arr[10]</code> when array has length 3</li>
</ul>
</li>
</ul>
<p>Things that we&#39;re not catching (for now) that we probably should</p>
<ul>
<li><strong>Warning:</strong> For-loop with <code>pvar</code> condition:<ul>
<li><code>for (int i = 0; i &lt; my_pvar; i++)</code> is a non-deterministic iteration count
  ` This should probably be an error</li>
</ul>
</li>
<li><strong>Warning:</strong> Uninitialized <code>pvar</code> read<ul>
<li><code>pvar&lt;int&gt; x; led_set(x);</code> - x could be undefined</li>
</ul>
</li>
<li><strong>Error:</strong> Scalar declared inside loop<ul>
<li><code>for (;;) { int counter = 0; }</code> - re-declares every frame</li>
<li>Should be caught</li>
</ul>
</li>
<li><strong>Error:</strong> Array subscript with non-integer<ul>
<li><code>arr[1.5]</code> or <code>arr[pvar_value]</code> (the second is actually legal!)</li>
<li>We allow pvar subscripts for <code>lfsr[my_lfsr_idx]</code></li>
</ul>
</li>
</ul>
<h3 id="compiler-settings">Compiler Settings</h3>
<p>The toolchain enforces specific compiler settings:</p>
<ul>
<li><code>-fno-fast-math</code> — guarantees floating-point reproducibility in reductions/scans</li>
<li>Standard optimization flags as appropriate for the target</li>
</ul>
<h3 id="backends">Backends</h3>
<p><strong>Simulator backend:</strong></p>
<p>Compiles to run on desktop with N virtual processors (configurable, typically 16 or 64 for testing). Used for debugging and algorithm development.</p>
<pre><code class="language-bash">./starc_pp.py src/algorithm.starc -o build/algorithm.c
gcc -DSTAR_SIM -Ilibstar build/algorithm.c libstar/sim_backend.c -o build/sim
./build/sim
</code></pre>
<p><strong>Hardware backend:</strong></p>
<p>Compiles for actual RISC-V nodes. Links against TDMA runtime.</p>
<pre><code class="language-bash">./starc_pp.py src/algorithm.starc -o build/algorithm.c
riscv-gcc -DSTAR_HW -Ilibstar build/algorithm.c libstar/hw_backend.c -o build/firmware.elf
</code></pre>
<hr>
<h2 id="chapter-10-runtime">Chapter 10: Runtime</h2>
<p>This chapter describes the runtime library and hardware interface.</p>
<h3 id="exchange-block-compilation">Exchange Block Compilation</h3>
<p>The preprocessor transforms an exchange block into runtime calls:</p>
<pre><code class="language-c">exchange {
    a = nbr(0, x);
    b = nbr(5, y);
    total = reduce_sum(z);
}
</code></pre>
<p>Becomes:</p>
<pre><code class="language-c">{
    star_ex_t __ex;
    star_ex_begin(&amp;__ex);
    
    star_ex_nbr(&amp;__ex, 0, &amp;a, &amp;x, sizeof(x));
    star_ex_nbr(&amp;__ex, 5, &amp;b, &amp;y, sizeof(y));
    star_ex_reduce(&amp;__ex, STAR_SUM, &amp;total, &amp;z, sizeof(z));
    
    star_ex_execute(&amp;__ex);  // Blocks until complete
}
</code></pre>
<p>The <code>star_ex_t</code> structure collects exchange declarations. <code>star_ex_execute()</code> validates capacity, schedules phases, and executes.</p>
<h3 id="fpga-interface">FPGA Interface</h3>
<p>The MCU communicates with the FPGA via memory-mapped registers:</p>
<table>
<thead>
<tr>
<th>Address</th>
<th>Register</th>
<th>Description</th>
</tr>
</thead>
<tbody><tr>
<td>0x4000_0000</td>
<td>PHASE_COUNTER</td>
<td>Current phase (0-23)</td>
</tr>
<tr>
<td>0x4000_0004</td>
<td>PHASE_CONFIG</td>
<td>Phase clock divider</td>
</tr>
<tr>
<td>0x4000_0008</td>
<td>TX_DATA</td>
<td>Transmit FIFO</td>
</tr>
<tr>
<td>0x4000_000C</td>
<td>RX_DATA</td>
<td>Receive FIFO</td>
</tr>
<tr>
<td>0x4000_0010</td>
<td>TX_STATUS</td>
<td>TX FIFO status</td>
</tr>
<tr>
<td>0x4000_0014</td>
<td>RX_STATUS</td>
<td>RX FIFO status</td>
</tr>
<tr>
<td>0x4000_0018</td>
<td>DIM_SELECT</td>
<td>Current dimension (pin mux)</td>
</tr>
<tr>
<td>0x4000_001C</td>
<td>FRAME_COUNT</td>
<td>Superframes since reset</td>
</tr>
<tr>
<td>0x4000_0020</td>
<td>ERROR_COUNT</td>
<td>CRC errors per dimension</td>
</tr>
</tbody></table>
<h3 id="phase-rate-configuration">Phase Rate Configuration</h3>
<pre><code class="language-c">void star_set_phase_rate(int hz);
</code></pre>
<p>Sets the FPGA&#39;s phase clock divider. Valid values: 100, 1000, 10000.</p>
<table>
<thead>
<tr>
<th>Rate</th>
<th>Superframe</th>
<th>Payload</th>
</tr>
</thead>
<tbody><tr>
<td>100 Hz</td>
<td>240 ms</td>
<td>800 B</td>
</tr>
<tr>
<td>1 kHz</td>
<td>24 ms</td>
<td>80 B</td>
</tr>
<tr>
<td>10 kHz</td>
<td>2.4 ms</td>
<td>8 B</td>
</tr>
</tbody></table>
<h3 id="error-handling">Error Handling</h3>
<p><strong>CRC errors:</strong></p>
<p>Each received frame is CRC-checked. On failure:</p>
<ol>
<li>Error counter for that dimension increments</li>
<li>Payload is zeroed</li>
<li>Execution continues</li>
</ol>
<p>Query errors:</p>
<pre><code class="language-c">int star_crc_errors(int dim);  // Errors on dimension dim
void star_clear_errors(void);  // Reset all counters
</code></pre>
<p><strong>Capacity exceeded:</strong></p>
<p>If an exchange block declares more than fits in one superframe, the runtime aborts with an error message. This is deliberate—automatic splitting would hide costs.</p>
<p><strong>Desynchronization:</strong></p>
<p>If the TDMA clock drifts or a processor crashes, the watchdog timer triggers a hardware reset. There is no automatic recovery.</p>
<hr>
<h1 id="appendices">Appendices</h1>
<hr>
<h2 id="appendix-a-quick-reference">Appendix A: Quick Reference</h2>
<h3 id="types-and-identity">Types and Identity</h3>
<pre><code class="language-c">pvar&lt;T&gt;              // Parallel variable (one per processor)
int pid()            // Processor ID (0-4095)
int coord(int dim)   // Bit &#39;dim&#39; of address (0 or 1)
int grid_row()       // Grid row (0-63)
int grid_col()       // Grid column (0-63)
</code></pre>
<h3 id="communication-exchange-blocks-only">Communication (exchange blocks only)</h3>
<pre><code class="language-c">// Neighbor exchange
T nbr(int dim, T val)              // Hypercube neighbor
T news(dir, T val)                 // Grid neighbor (N/E/S/W)

// Reductions → scalar
T reduce_sum(pvar&lt;T&gt;)
T reduce_min(pvar&lt;T&gt;)
T reduce_max(pvar&lt;T&gt;)
T reduce_and(pvar&lt;T&gt;)
T reduce_or(pvar&lt;T&gt;)

// Scans → pvar
pvar&lt;T&gt; scan_sum(pvar&lt;T&gt;)              // Exclusive
pvar&lt;T&gt; scan_min(pvar&lt;T&gt;)              // Exclusive
pvar&lt;T&gt; scan_max(pvar&lt;T&gt;)              // Exclusive
pvar&lt;T&gt; scan_sum_inclusive(pvar&lt;T&gt;)    // Inclusive
pvar&lt;T&gt; scan_min_inclusive(pvar&lt;T&gt;)    // Inclusive
pvar&lt;T&gt; scan_max_inclusive(pvar&lt;T&gt;)    // Inclusive

// Broadcast
pvar&lt;T&gt; broadcast(int source, T val)
</code></pre>
<h3 id="control">Control</h3>
<pre><code class="language-c">if (scalar_cond) { }     // Uniform (all same branch)
where (pvar_cond) { }    // Divergent (per-processor)
exchange { }             // Synchronous communication
exchange_async { }       // Asynchronous communication
exchange_wait()          // Wait for async
barrier()                // Global sync (rarely needed)
</code></pre>
<h3 id="io-control-tree">I/O (control tree)</h3>
<pre><code class="language-c">void led_set(uint8_t brightness)
uint8_t led_get(void)
void load_from_host(pvar&lt;T&gt;*, size_t)
void store_to_host(pvar&lt;T&gt;*, size_t)
void host_printf(const char*, ...)
</code></pre>
<h3 id="configuration">Configuration</h3>
<pre><code class="language-c">void star_set_phase_rate(int hz)   // 100, 1000, or 10000
int star_crc_errors(int dim)
void star_clear_errors(void)
</code></pre>
<hr>
<h2 id="appendix-b-what-starc-doesn39t-have">Appendix B: What StarC Doesn&#39;t Have</h2>
<p><strong>No <code>get(address)</code> or <code>send(address, value)</code>.</strong></p>
<p>Arbitrary point-to-point communication would require routing through intermediate nodes. We have no router—only neighbor links and a TDMA schedule. Algorithms requiring arbitrary permutation should use a GPU or other architecture.</p>
<p><strong>No virtual processors.</strong></p>
<p>The CM-1 could simulate more processors than physically existed. StarC has exactly 4,096 processors. Problem size must be 4,096 or adapted to fit.</p>
<p><strong>No variable payload sizes.</strong></p>
<p>80 bytes per phase at 1 kHz. Pack your structs accordingly, or use a slower phase rate for larger payloads.</p>
<p><strong>No automatic multi-superframe splitting.</strong></p>
<p>If your exchange block exceeds capacity, you get a runtime error. This is deliberate—hidden costs make performance unpredictable. Split your blocks explicitly.</p>
<p><strong>No automatic error recovery.</strong></p>
<p>CRC failures zero the payload and increment a counter. Desynchronization triggers hardware reset. The machine does not attempt to recover from errors automatically.</p>
<hr>
<h2 id="appendix-c-constants">Appendix C: Constants</h2>
<pre><code class="language-c">#define STAR_PROCESSORS      4096
#define STAR_DIMENSIONS      12
#define STAR_GRID_SIZE       64
#define STAR_MAX_PAYLOAD     80    // bytes, at 1 kHz
#define STAR_SUPERFRAME_MS   24    // at 1 kHz
#define STAR_PHASES          24
</code></pre>
<hr>
<h2 id="appendix-d-reduction-and-scan-order">Appendix D: Reduction and Scan Order</h2>
<p>All tree operations proceed <strong>dimension 0 first, ascending to dimension 11</strong>.</p>
<p><strong>Reduction sequence:</strong></p>
<ol>
<li>Exchange with dimension 0 neighbor, combine</li>
<li>Exchange with dimension 1 neighbor, combine</li>
<li>Exchange with dimension 2 neighbor, combine</li>
<li>...</li>
<li>Exchange with dimension 11 neighbor, combine</li>
<li>All processors have global result</li>
</ol>
<p><strong>Floating-point guarantee:</strong></p>
<p>This ordering is fixed and guaranteed. Combined with the toolchain&#39;s <code>-fno-fast-math</code> enforcement, identical inputs always produce bit-identical outputs. Reproducibility is not optional.</p>
<hr>
<h1 id="finally">Finally...</h1>
<p>StarC was developed in parallel (heh) with the design of a hypercube computer using TDMA for communication. The hardware influenced the programming model, and the programming model influenced the hardware. They are inseparable. StarC is simply just a Python preprocessor that emits C code because I didn&#39;t want to fork GCC to implement all this weird stuff. This is the minimum viable language for a strange bit of hardware. It&#39;s not revolutionary, and it will never sit even at the bottom of the TIOBE index. But this doesn&#39;t mean it&#39;s not useful.</p>
<p>C was created as a thin wrapper over the PDP-11, or a PDP-7, depending on how far back you want to go. StarC is a thin wrapper over a hypercube. It&#39;s not an abstraction; it&#39;s the language you use to program this specific piece of hardware.</p>
<p>StarC is not meant to be the perfect language. In fact, the TDMA protocol used for communication in this machine can be much more expressive than StarC allows. Multi-hop routing is possible with the TDMA protocol, but it is unimplemented in StarC simply because the interesting algorithms made possible in a hypercube computer simply do not need multi-hop routing. But what <em>is</em> implemented allows the machine to be programmed, and those interesting algorithms to be expressed cleanly. That&#39;s what StarC is for, not to be the perfect language, but to be the language that makes this machine programmable.</p>
<hr>
<p><a href="ThinkinMachine.html">back to main project page</a></p>
<p><a href="../">main</a></p>
</div><!-- /.tm-article -->
</div><!-- /.tm-layout -->

<script>
// Tell default.html to skip its automatic code block processing
// This MUST run synchronously before DOMContentLoaded
if (document.body) {
  document.body.setAttribute('data-custom-code-blocks', 'true');
  console.log('StarC: Set custom code blocks attribute');
} else {
  console.error('StarC: Body not available');
}
</script>

<script>
document.addEventListener("DOMContentLoaded", () => {
  console.log('StarC: DOMContentLoaded fired');

  // Handle collapsible code blocks
  const setupCollapsibleCodeBlocks = () => {
    console.log('StarC: Setting up collapsible code blocks');

    // Remove all auto-generated wrappers that AREN'T marked collapsible
    const defaultWrappers = document.querySelectorAll('.code-block-wrapper:not(.collapsible)');
    console.log(`StarC: Found ${defaultWrappers.length} default wrappers to remove`);

    defaultWrappers.forEach(wrapper => {
      const content = wrapper.querySelector('.code-block-content');
      const pre = content ? content.querySelector('pre') : wrapper.querySelector('pre');
      if (pre && wrapper.parentNode) {
        wrapper.parentNode.insertBefore(pre, wrapper);
        wrapper.remove();
      }
    });

    // Find all code blocks that are preceded by <!-- COLLAPSIBLE --> comment
    const walker = document.createTreeWalker(
      document.body,
      NodeFilter.SHOW_COMMENT,
      null
    );

    const collapsibleBlocks = [];
    let comment;
    let commentCount = 0;
    while (comment = walker.nextNode()) {
      commentCount++;
      console.log(`StarC: Found comment: "${comment.nodeValue.trim()}"`);
      if (comment.nodeValue.trim() === 'COLLAPSIBLE') {
        console.log('StarC: Found COLLAPSIBLE marker');
        // Find the next code block after this comment
        let node = comment.nextSibling;
        let siblingCount = 0;
        while (node && siblingCount < 10) {
          siblingCount++;
          console.log(`StarC: Checking sibling ${siblingCount}: ${node.nodeType} ${node.nodeName}`);
          if (node.nodeType === Node.ELEMENT_NODE) {
            // Check if this element is a PRE directly
            if (node.tagName === 'PRE') {
              console.log('StarC: Found PRE after COLLAPSIBLE');
              collapsibleBlocks.push(node);
              break;
            }
            // Check if this element contains a PRE (Jekyll wraps in DIV)
            const preInside = node.querySelector('pre[class*="language-"]');
            if (preInside) {
              console.log('StarC: Found PRE inside DIV after COLLAPSIBLE');
              collapsibleBlocks.push(preInside);
              break;
            }
          }
          node = node.nextSibling;
        }
      }
    }
    console.log(`StarC: Total comments found: ${commentCount}`);
    console.log(`StarC: Collapsible blocks to create: ${collapsibleBlocks.length}`);

    // Wrap each collapsible code block
    collapsibleBlocks.forEach((codeBlock) => {
      // Skip if already wrapped
      if (codeBlock.closest('.code-block-wrapper.collapsible')) return;

      // Get the language from the class
      const languageClass = Array.from(codeBlock.classList)
        .find(className => className.startsWith('language-'));
      const language = languageClass ? languageClass.replace('language-', '') : 'code';

      // Create wrapper structure
      const wrapper = document.createElement('div');
      wrapper.className = 'code-block-wrapper collapsible';

      const header = document.createElement('div');
      header.className = 'code-block-header';

      const title = document.createElement('div');
      title.className = 'code-block-title';
      title.textContent = language.charAt(0).toUpperCase() + language.slice(1);

      const toggle = document.createElement('div');
      toggle.className = 'code-block-toggle';
      toggle.textContent = 'Show code';

      const content = document.createElement('div');
      content.className = 'code-block-content';

      // Assemble structure
      header.appendChild(title);
      header.appendChild(toggle);
      wrapper.appendChild(header);

      // Move code block into wrapper
      codeBlock.parentNode.insertBefore(wrapper, codeBlock);
      content.appendChild(codeBlock);
      wrapper.appendChild(content);

      // Ensure collapsed state initially (remove expanded class if present)
      content.classList.remove('expanded');
      content.style.display = 'none';

      // Add click handler
      header.addEventListener('click', function() {
        content.classList.toggle('expanded');
        if (content.classList.contains('expanded')) {
          content.style.display = 'block';
          toggle.textContent = 'Hide code';
        } else {
          content.style.display = 'none';
          toggle.textContent = 'Show code';
        }
      });
    });
  };

  // Run immediately
  setupCollapsibleCodeBlocks();

  // Run again after a short delay to catch any late additions
  setTimeout(setupCollapsibleCodeBlocks, 100);

  // Also run when Prism finishes highlighting
  if (window.Prism) {
    Prism.hooks.add('after-highlight', setupCollapsibleCodeBlocks);
  }

  const root     = document.documentElement;
  const layoutEl = document.querySelector(".tm-layout") || document.body;
  const articleEl= document.querySelector(".tm-article") || layoutEl;
  const tocEl    = document.querySelector(".tm-toc");
  const tocList  = document.getElementById("tm-toc");
  const navEl    = document.querySelector(".navbar");

  if (!tocList || !tocEl) return;

  // ---------- Build ToC ----------
  tocList.innerHTML = "";

  const headings = Array.from(articleEl.querySelectorAll("h1, h2, h3, h4"))
    .filter(h => !h.closest(".tm-toc") && !h.closest(".starc-header"));

  if (!headings.length) {
    tocEl.style.display = "none";
    return;
  } else {
    tocEl.style.display = "";
  }

  const slugify = (s) => (s || "")
    .trim()
    .toLowerCase()
    .replace(/[^\w\- ]+/g, "")
    .replace(/\s+/g, "-")
    .replace(/\-+/g, "-")
    .replace(/^\-|\-$/g, "");

  const used = new Set();

  headings.forEach(h => {
    if (!h.id) {
      let base = slugify(h.textContent) || "section";
      let id = base, n = 2;
      while (used.has(id) || document.getElementById(id)) id = `${base}-${n++}`;
      h.id = id;
    }
    used.add(h.id);

    const li = document.createElement("li");
    const tag = h.tagName.toLowerCase();
    li.classList.add(
      tag === "h1" ? "tm-toc-level-1" :
      tag === "h2" ? "tm-toc-level-2" :
      tag === "h3" ? "tm-toc-level-3" : "tm-toc-level-4"
    );

    const a = document.createElement("a");
    a.href = `#${h.id}`;
    a.textContent = h.textContent;

    li.appendChild(a);
    tocList.appendChild(li);
  });

  // ---------- Layout sync ----------
  const px = (n) => `${Math.max(0, Math.round(n))}px`;

  function syncLayout() {
    const navH = navEl ? navEl.getBoundingClientRect().height : 0;
    root.style.setProperty("--tm-nav-h", px(navH));
    root.style.setProperty("--tm-scroll-offset", px(navH + 12));

    const desktop = window.matchMedia("(min-width: 900px)").matches;
    if (!desktop) {
      layoutEl.classList.add("tm-stack");
      root.style.setProperty("--tm-article-fit-px", "100000px");
      return;
    }

    layoutEl.classList.remove("tm-stack");

    const vw = document.documentElement.clientWidth;

    // Don't override the CSS --tm-toc-max-px, respect what's set in CSS
    // This allows manual control of ToC width

    const tocW = tocEl ? tocEl.getBoundingClientRect().width : 0;
    const gap = 32; // Increased gap between ToC and article
    const articleFit = vw - tocW - gap;
    root.style.setProperty("--tm-article-fit-px", px(articleFit));
  }

  syncLayout();
  window.addEventListener("resize", syncLayout);

  // ---------- Active section highlight ----------
  const tocLinks = Array.from(tocList.querySelectorAll("a"));
  const linkById = new Map(
    tocLinks.map(a => [decodeURIComponent(a.getAttribute("href").slice(1)), a])
  );

  let activeLi = null;

  const obs = new IntersectionObserver(
    (entries) => {
      for (const e of entries) {
        if (e.isIntersecting) {
          const link = linkById.get(e.target.id);
          if (link) {
            if (activeLi) {
              activeLi.classList.remove("is-active");
              activeLi.querySelector("a")?.classList.remove("is-active");
            }
            activeLi = link.parentElement;
            activeLi.classList.add("is-active");
            link.classList.add("is-active");
          }
        }
      }
    },
    {
      rootMargin: "-10% 0px -85% 0px",
      threshold: 0
    }
  );

  headings.forEach(h => obs.observe(h));

  // Smooth scroll
  tocList.addEventListener("click", (e) => {
    if (e.target.tagName === "A") {
      e.preventDefault();
      const id = e.target.getAttribute("href").slice(1);
      const target = document.getElementById(id);
      if (target) {
        const offset = parseFloat(getComputedStyle(root).getPropertyValue("--tm-scroll-offset")) || 90;
        const top = target.getBoundingClientRect().top + window.scrollY - offset;
        window.scrollTo({ top, behavior: "smooth" });
      }
    }
  });
});
</script>
        </main>
    </div>

    <button class="mobile-menu-btn" id="mobile-menu-btn" aria-label="Toggle menu">☰</button>

    <script>
        // Mobile menu toggle
        const sidebar = document.getElementById('sidebar');
        const mobileMenuBtn = document.getElementById('mobile-menu-btn');

        mobileMenuBtn.addEventListener('click', () => {
            sidebar.classList.toggle('open');
        });

        // Close sidebar when clicking outside on mobile
        document.addEventListener('click', (e) => {
            if (window.innerWidth <= 768 &&
                sidebar.classList.contains('open') &&
                !sidebar.contains(e.target) &&
                e.target !== mobileMenuBtn) {
                sidebar.classList.remove('open');
            }
        });

        // Collapsible code block toggles
        document.querySelectorAll('.code-block-header').forEach(header => {
            header.addEventListener('click', () => {
                const wrapper = header.closest('.code-block-wrapper');
                const content = wrapper.querySelector('.code-block-content');
                const toggle = wrapper.querySelector('.code-block-toggle');

                content.classList.toggle('expanded');
                toggle.textContent = content.classList.contains('expanded') ? 'Hide Code' : 'Show Code';
            });
        });

        // Smooth scroll for TOC links
        document.querySelectorAll('.toc a').forEach(link => {
            link.addEventListener('click', (e) => {
                e.preventDefault();
                const targetId = link.getAttribute('href').substring(1);
                const target = document.getElementById(targetId);
                if (target) {
                    target.scrollIntoView({ behavior: 'smooth', block: 'start' });
                    window.history.pushState(null, '', '#' + targetId);

                    // Close mobile menu
                    if (window.innerWidth <= 768) {
                        sidebar.classList.remove('open');
                    }
                }
            });
        });

        // Handle initial hash navigation
        if (window.location.hash) {
            setTimeout(() => {
                const element = document.querySelector(window.location.hash);
                if (element) element.scrollIntoView({ behavior: 'smooth' });
            }, 100);
        }
    </script>
</body>
</html>
